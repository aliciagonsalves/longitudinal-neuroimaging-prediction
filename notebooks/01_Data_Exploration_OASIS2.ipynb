{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37986d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In: notebooks/01_Data_Exploration_OASIS2.ipynb\n",
    "# Purpose: Load OASIS-2 clinical data using config, perform detailed exploration\n",
    "#          (including longitudinal aspects), verify MPRAGE file presence,\n",
    "#          log results efficiently to W&B, and save key outputs locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ae22bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Import Libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de82623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Config Loading ---\n",
    "print(\"--- Loading Configuration ---\")\n",
    "CONFIG_PATH = Path('../config.json')\n",
    "try:\n",
    "    # --- Determine Project Root ---\n",
    "    # Assumes config.json is in the project root directory\n",
    "    PROJECT_ROOT = CONFIG_PATH.parent.resolve()\n",
    "    print(f\"Project Root detected as: {PROJECT_ROOT}\")\n",
    "\n",
    "    with open(CONFIG_PATH, 'r', encoding='utf-8') as f: # Added encoding just in case\n",
    "        config = json.load(f)\n",
    "    print(\"Configuration loaded successfully.\")\n",
    "\n",
    "    # --- Resolve paths relative to PROJECT_ROOT ---\n",
    "    INPUT_DATA_PATH = PROJECT_ROOT / config['data']['clinical_excel_path']\n",
    "    MRI_BASE_PATHS = [PROJECT_ROOT / p for p in config['data']['mri_base_paths']]\n",
    "    OUTPUT_DIR_BASE = PROJECT_ROOT / config['data']['output_dir_base']\n",
    "    # --- (End of path resolution) ---\n",
    "\n",
    "    MPR_IMG_PATTERN = re.compile(config['mri_verification']['mpr_img_pattern'])\n",
    "    WANDB_PROJECT = config['wandb']['project_name']\n",
    "    WANDB_ENTITY = config['wandb'].get('entity', None)\n",
    "\n",
    "    NOTEBOOK_NAME = \"01_Data_Exploration\"\n",
    "    output_dir = OUTPUT_DIR_BASE / NOTEBOOK_NAME\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Outputs will be saved to: {output_dir}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Configuration file not found at {CONFIG_PATH}\")\n",
    "    print(\"Please ensure 'config.json' exists in the project root.\")\n",
    "    exit()\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Missing key {e} in configuration file.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred loading the config file: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c4fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Functions ---\n",
    "print(\"\\n--- Defining Helper Functions ---\")\n",
    "\n",
    "def finalize_plot(fig, run, wandb_key, save_path):\n",
    "    \"\"\"Handles logging plot to W&B, saving locally, showing, and closing.\"\"\"\n",
    "    if run:\n",
    "        run.log({wandb_key: wandb.Image(fig)})\n",
    "    if save_path:\n",
    "        try:\n",
    "            fig.savefig(save_path, bbox_inches='tight') # Use bbox_inches for better layout saving\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not save plot to {save_path}. Error: {e}\")\n",
    "    plt.show()\n",
    "    plt.close(fig) # Close the specific figure\n",
    "\n",
    "def verify_scan_files(row, base_paths, pattern):\n",
    "    \"\"\"Verifies presence of img/hdr pairs for a given clinical data row.\"\"\"\n",
    "    subject_id = row['Subject ID']\n",
    "    mri_id = row['MRI ID']\n",
    "    mri_folder = None\n",
    "    found_in_path = None\n",
    "\n",
    "    log_entry = {\n",
    "        'mri_id': mri_id,\n",
    "        'subject_id': subject_id,\n",
    "        'visit': row.get('Visit', None),\n",
    "        'group': row.get('Group', None),\n",
    "    }\n",
    "\n",
    "    for base_path in base_paths:\n",
    "        potential_folder = base_path / mri_id / 'RAW'\n",
    "        if potential_folder.is_dir():\n",
    "            mri_folder = potential_folder\n",
    "            found_in_path = str(base_path) # Store as string for logging\n",
    "            break\n",
    "\n",
    "    log_entry['mri_base_path_used'] = found_in_path\n",
    "\n",
    "    if mri_folder is None:\n",
    "        log_entry.update({\n",
    "            'mri_folder_exists': False,\n",
    "            'mri_folder_is_dir': False,\n",
    "            'mprs_found_count': 0,\n",
    "            'mpr_labels_found': [],\n",
    "            'found_three_or_more_mprs': False\n",
    "        })\n",
    "        return log_entry\n",
    "\n",
    "    log_entry['mri_folder_exists'] = True\n",
    "    log_entry['mri_folder_is_dir'] = True\n",
    "    found_mpr_pairs = {}\n",
    "\n",
    "    try:\n",
    "        filenames = [f.name for f in mri_folder.iterdir()] # Use pathlib\n",
    "    except OSError as e:\n",
    "        log_entry.update({\n",
    "            'mprs_found_count': 0,\n",
    "            'error_listing_dir': str(e),\n",
    "            'mpr_labels_found': [],\n",
    "            'found_three_or_more_mprs': False\n",
    "        })\n",
    "        return log_entry\n",
    "\n",
    "    for filename in filenames:\n",
    "        match = pattern.match(filename)\n",
    "        if match:\n",
    "            mpr_label = match.group(1)\n",
    "            hdr_filename = f\"{mpr_label}.nifti.hdr\"\n",
    "            hdr_path = mri_folder / hdr_filename\n",
    "            img_path = mri_folder / filename\n",
    "\n",
    "            if hdr_path.is_file(): # Check if header file exists\n",
    "                found_mpr_pairs[mpr_label] = (str(img_path), str(hdr_path))\n",
    "\n",
    "    num_found = len(found_mpr_pairs)\n",
    "    log_entry.update({\n",
    "        'mprs_found_count': num_found,\n",
    "        'mpr_labels_found': sorted(list(found_mpr_pairs.keys())),\n",
    "        'found_three_or_more_mprs': num_found >= 3\n",
    "    })\n",
    "    return log_entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5f2c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialize W&B Run ---\n",
    "print(\"\\n--- Initializing Weights & Biases Run ---\")\n",
    "try:\n",
    "    run = wandb.init(\n",
    "        project=WANDB_PROJECT,\n",
    "        entity=WANDB_ENTITY,\n",
    "        job_type=\"data-exploration-validation\",\n",
    "        name=f\"{NOTEBOOK_NAME}-run-{time.strftime('%Y%m%d-%H%M')}\",\n",
    "        config={ # Log configuration parameters derived from the loaded config\n",
    "            \"input_data_path\": str(INPUT_DATA_PATH),\n",
    "            \"mri_base_paths\": [str(p) for p in MRI_BASE_PATHS],\n",
    "            \"mpr_img_pattern\": MPR_IMG_PATTERN.pattern,\n",
    "            \"output_dir\": str(output_dir),\n",
    "            \"execution_date\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "    )\n",
    "    print(f\"W&B run '{run.name}' initialized successfully (ID: {run.id}). View at: {run.url}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing W&B: {e}\")\n",
    "    print(\"Proceeding without W&B logging.\")\n",
    "    run = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7a204f",
   "metadata": {},
   "source": [
    "## Load Clinical Data\n",
    "\n",
    "Load the raw longitudinal clinical and demographic data from the specified Excel file using pandas. We also initialize Weights & Biases here to track this exploration run and log the source data as an artifact for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736fde7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- Loading Clinical Data from: {INPUT_DATA_PATH} ---\")\n",
    "try:\n",
    "    # Make sure the file path exists before trying to read\n",
    "    if not INPUT_DATA_PATH.is_file():\n",
    "         raise FileNotFoundError(f\"Input data file not found at {INPUT_DATA_PATH}\")\n",
    "\n",
    "    clinical_df = pd.read_excel(INPUT_DATA_PATH)\n",
    "    print(f\"Data loaded successfully. Shape: {clinical_df.shape}\")\n",
    "\n",
    "    if clinical_df.empty:\n",
    "        print(\"Error: Loaded dataframe is empty.\")\n",
    "        if run: run.finish()\n",
    "        exit()\n",
    "\n",
    "    if run:\n",
    "        # Log a summary artifact of the input table\n",
    "        print(\"Logging raw data as W&B artifact...\")\n",
    "        raw_data_at = wandb.Artifact(f\"{INPUT_DATA_PATH.stem}_raw\", type=\"dataset\",\n",
    "                                     description=f\"Raw clinical data from {INPUT_DATA_PATH.name}\",\n",
    "                                     metadata={\"shape\": clinical_df.shape, \"source_path\": str(INPUT_DATA_PATH)})\n",
    "        # Adding the file to the artifact (W&B handles upload)\n",
    "        try:\n",
    "             raw_data_at.add_file(str(INPUT_DATA_PATH))\n",
    "             run.log_artifact(raw_data_at)\n",
    "             print(\"Raw data artifact logged.\")\n",
    "        except Exception as e:\n",
    "             print(f\"Warning: Could not add file to W&B artifact. Error: {e}\")\n",
    "\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    if run: run.finish()\n",
    "    exit()\n",
    "except ImportError: # More specific error for missing excel readers\n",
    "     print(f\"Error loading Excel file: Missing library.\")\n",
    "     print(\"You might need to install 'openpyxl' (`pip install openpyxl`)\")\n",
    "     if run: run.finish()\n",
    "     exit()\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred loading the data file: {e}\")\n",
    "    if run: run.finish()\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a687bdf",
   "metadata": {},
   "source": [
    "## Initial Data Inspection\n",
    "\n",
    "Perform basic checks on the loaded `clinical_df_raw` DataFrame:\n",
    "* View data types, non-null counts, memory usage (`.info()`).\n",
    "* Calculate descriptive statistics for all columns (`.describe(include='all')`).\n",
    "* Identify and count missing values per column (`.isnull().sum()`).\n",
    "Log summary statistics derived from these checks to Weights & Biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e2fc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Basic Data Information ---\")\n",
    "print(\"DataFrame Info:\")\n",
    "clinical_df.info()\n",
    "\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "desc_stats = clinical_df.describe(include='all')\n",
    "print(desc_stats)\n",
    "# Save descriptive stats locally\n",
    "desc_stats_path = output_dir / 'descriptive_stats.csv'\n",
    "try:\n",
    "    desc_stats.to_csv(desc_stats_path)\n",
    "    print(f\"Descriptive stats saved to {desc_stats_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not save descriptive stats. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f4c177",
   "metadata": {},
   "source": [
    "### Missing Value Strategy Note\n",
    "\n",
    "Acknowledge the identified missing values (especially in columns like MMSE, SES). Note that a specific strategy for handling these (e.g., imputation) will be decided upon and implemented during the preprocessing stage *after* the data has been split into train/validation/test sets to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254256a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing Values per Column (Only showing columns with missing values):\")\n",
    "missing_values = clinical_df.isnull().sum()\n",
    "missing_values_filtered = missing_values[missing_values > 0]\n",
    "print(missing_values_filtered)\n",
    "# Save missing values summary locally\n",
    "missing_values_path = output_dir / 'missing_values_summary.csv'\n",
    "try:\n",
    "    missing_values_filtered.to_csv(missing_values_path, header=['missing_count'])\n",
    "    print(f\"Missing values summary saved to {missing_values_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not save missing values summary. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acb788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Log key stats to W&B ---\n",
    "if run:\n",
    "    print(\"\\nLogging summary statistics to W&B...\")\n",
    "    log_dict = {\n",
    "        'dataset/num_rows': clinical_df.shape[0],\n",
    "        'dataset/num_columns': clinical_df.shape[1],\n",
    "        'dataset/missing_values_total': int(missing_values.sum()),\n",
    "        'dataset/columns_with_missing_values': int(len(missing_values_filtered)),\n",
    "        'dataset/memory_usage_MB': clinical_df.memory_usage(deep=True).sum() / (1024**2)\n",
    "    }\n",
    "    # Add descriptive stats for key columns if they exist\n",
    "    for col in ['Age', 'EDUC', 'SES', 'MMSE', 'CDR', 'eTIV', 'nWBV', 'ASF']:\n",
    "        if col in desc_stats.columns:\n",
    "            # Check for non-numeric stats like 'unique', 'top', 'freq' if include='all' was used\n",
    "            stats_to_log = {k: v for k, v in desc_stats[col].dropna().items() if pd.api.types.is_number(v)}\n",
    "            log_dict.update({f'stats/{col}_{k}': v for k, v in stats_to_log.items()})\n",
    "\n",
    "    run.log(log_dict)\n",
    "    print(\"Summary statistics logged to W&B.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eee7913",
   "metadata": {},
   "source": [
    "## Analyze Variable Distributions\n",
    "\n",
    "Visualize the distributions of key individual variables using histograms (for numerical data like Age, MMSE, nWBV) and count plots (for categorical data like Group, Gender, or discrete counts like VisitsPerSubject). This helps understand the overall characteristics of the cohort across all recorded visits. Plots are logged to W&B and saved locally to the notebook's output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6d0185",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Analyzing Variable Distributions ---\")\n",
    "\n",
    "# Distribution of Age\n",
    "fig, ax = plt.subplots(figsize=(10, 5)) # Use subplots for more control\n",
    "sns.histplot(data=clinical_df, x='Age', kde=True, bins=20, ax=ax)\n",
    "ax.set_title('Distribution of Age')\n",
    "ax.set_xlabel('Age (Years)')\n",
    "ax.set_ylabel('Frequency')\n",
    "finalize_plot(fig, run, \"charts/distribution/age\", output_dir / 'age_distribution.png')\n",
    "\n",
    "# Distribution of MMSE scores\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.histplot(data=clinical_df.dropna(subset=['MMSE']), x='MMSE', kde=True, bins=15, ax=ax)\n",
    "ax.set_title('Distribution of MMSE Scores')\n",
    "ax.set_xlabel('MMSE Score')\n",
    "ax.set_ylabel('Frequency')\n",
    "finalize_plot(fig, run, \"charts/distribution/mmse\", output_dir / 'mmse_distribution.png')\n",
    "\n",
    "# Distribution of nWBV\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.histplot(data=clinical_df.dropna(subset=['nWBV']), x='nWBV', kde=True, bins=20, ax=ax)\n",
    "ax.set_title('Distribution of Normalized Whole Brain Volume (nWBV)')\n",
    "ax.set_xlabel('nWBV')\n",
    "ax.set_ylabel('Frequency')\n",
    "finalize_plot(fig, run, \"charts/distribution/nwbv\", output_dir / 'nwbv_distribution.png')\n",
    "\n",
    "# Count of Visits per Subject\n",
    "visits_per_subject = clinical_df['Subject ID'].value_counts()\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "sns.countplot(x=visits_per_subject, ax=ax)\n",
    "ax.set_title('Number of Visits per Subject')\n",
    "ax.set_xlabel('Number of Visits')\n",
    "ax.set_ylabel('Number of Subjects')\n",
    "finalize_plot(fig, run, \"charts/distribution/visits_per_subject\", output_dir / 'visits_per_subj.png')\n",
    "\n",
    "# Distribution of Clinical Groups\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "group_order = clinical_df['Group'].value_counts().index # Determine order dynamically\n",
    "sns.countplot(data=clinical_df, x='Group', order=group_order, ax=ax)\n",
    "ax.set_title('Distribution of Clinical Groups (All Visits)')\n",
    "ax.set_xlabel('Group')\n",
    "ax.set_ylabel('Number of Visits/Scans')\n",
    "finalize_plot(fig, run, \"charts/distribution/group\", output_dir / 'clinical_groups_distribution.png')\n",
    "\n",
    "# Distribution of Gender\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "sns.countplot(data=clinical_df, x='M/F', ax=ax)\n",
    "ax.set_title('Distribution of Gender (All Visits)')\n",
    "ax.set_xlabel('Gender')\n",
    "ax.set_ylabel('Number of Visits/Scans')\n",
    "finalize_plot(fig, run, \"charts/distribution/gender\", output_dir / 'gender_distribution.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b59d274",
   "metadata": {},
   "source": [
    "## Analyze Relationships Between Variables\n",
    "\n",
    "Explore potential pairwise relationships between important variables. This includes:\n",
    "* Scatter plots to visualize relationships like Age vs. MMSE, Age vs. nWBV, colored by clinical group.\n",
    "* A correlation matrix heatmap for key numerical variables to quantify linear associations.\n",
    "Plots are logged to W&B and saved locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b5e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Analyzing Relationships Between Variables ---\")\n",
    "\n",
    "# Age vs. MMSE score\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.scatterplot(data=clinical_df, x='Age', y='MMSE', hue='Group', alpha=0.6, ax=ax, hue_order=group_order)\n",
    "ax.set_title('Age vs. MMSE Score by Group')\n",
    "ax.set_xlabel('Age (Years)')\n",
    "ax.set_ylabel('MMSE Score')\n",
    "finalize_plot(fig, run, \"charts/relationship/age_vs_mmse\", output_dir / 'age_mmse.png')\n",
    "\n",
    "# Age vs. nWBV\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.scatterplot(data=clinical_df, x='Age', y='nWBV', hue='Group', alpha=0.6, ax=ax, hue_order=group_order)\n",
    "ax.set_title('Age vs. Normalized Whole Brain Volume (nWBV) by Group')\n",
    "ax.set_xlabel('Age (Years)')\n",
    "ax.set_ylabel('nWBV')\n",
    "finalize_plot(fig, run, \"charts/relationship/age_vs_nwbv\", output_dir / 'age_nwbv.png')\n",
    "\n",
    "# MMSE vs. nWBV\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.scatterplot(data=clinical_df.dropna(subset=['MMSE', 'nWBV']), x='MMSE', y='nWBV', hue='Group', alpha=0.6, ax=ax, hue_order=group_order)\n",
    "ax.set_title('MMSE vs. Normalized Whole Brain Volume (nWBV) by Group')\n",
    "ax.set_xlabel('MMSE Score')\n",
    "ax.set_ylabel('nWBV')\n",
    "finalize_plot(fig, run, \"charts/relationship/mmse_vs_nwbv\", output_dir / 'mmse_nwbv.png')\n",
    "\n",
    "# Correlation Heatmap\n",
    "numerical_cols = ['Age', 'EDUC', 'SES', 'MMSE', 'CDR', 'eTIV', 'nWBV', 'ASF', 'Visit'] # Added Visit\n",
    "valid_numerical_cols = [col for col in numerical_cols if col in clinical_df.columns and pd.api.types.is_numeric_dtype(clinical_df[col])]\n",
    "if valid_numerical_cols:\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    correlation_matrix = clinical_df[valid_numerical_cols].corr()\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", ax=ax, annot_kws={\"size\": 8}) # Smaller annotation font\n",
    "    ax.set_title('Correlation Matrix of Key Numerical Variables')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    fig.tight_layout() # Use figure's tight_layout\n",
    "    finalize_plot(fig, run, \"charts/relationship/correlation_heatmap\", output_dir / 'corr_matrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f3c6f9",
   "metadata": {},
   "source": [
    "## Analyze Differences Between Clinical Groups\n",
    "\n",
    "Compare the distributions of key variables (e.g., MMSE, nWBV, Age) across the different clinical groups ('Nondemented', 'Converted', 'Demented') defined in the dataset. Box plots and violin plots are used for visualization. Plots are logged to W&B and saved locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb30392",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Analyzing Differences Between Clinical Groups ---\")\n",
    "group_order_analysis = ['Nondemented', 'Converted', 'Demented'] # Define consistent order\n",
    "\n",
    "# MMSE scores by group\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.boxplot(data=clinical_df, x='Group', y='MMSE', order=group_order_analysis, ax=ax)\n",
    "ax.set_title('MMSE Scores by Clinical Group')\n",
    "ax.set_xlabel('Clinical Group')\n",
    "ax.set_ylabel('MMSE Score')\n",
    "finalize_plot(fig, run, \"charts/group_comparison/mmse_boxplot\", output_dir / 'mmse_clinical_boxplot.png')\n",
    "\n",
    "# nWBV by group\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.boxplot(data=clinical_df, x='Group', y='nWBV', order=group_order_analysis, ax=ax)\n",
    "ax.set_title('nWBV by Clinical Group')\n",
    "ax.set_xlabel('Clinical Group')\n",
    "ax.set_ylabel('Normalized Whole Brain Volume (nWBV)')\n",
    "finalize_plot(fig, run, \"charts/group_comparison/nwbv_boxplot\", output_dir / 'nwbv_clinical_boxplot.png')\n",
    "\n",
    "# Age distribution by group\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.violinplot(data=clinical_df, x='Group', y='Age', order=group_order_analysis, ax=ax)\n",
    "ax.set_title('Age Distribution by Clinical Group')\n",
    "ax.set_xlabel('Clinical Group')\n",
    "ax.set_ylabel('Age (Years)')\n",
    "finalize_plot(fig, run, \"charts/group_comparison/age_violinplot\", output_dir / 'age_clinical_violinplot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eaba66",
   "metadata": {},
   "source": [
    "## Deeper Longitudinal Analysis\n",
    "\n",
    "Explore the time-based aspects of the data more explicitly:\n",
    "1.  **Visit Intervals:** Calculate the approximate time elapsed between consecutive visits for each subject and visualize the distribution of these intervals.\n",
    "2.  **Baseline Characteristics:** Filter the data to include only the first visit (`Visit == 1`) for each subject and analyze the distributions (Group, MMSE, Age) for this baseline cohort specifically.\n",
    "3.  **Average Trends:** Plot the average MMSE and nWBV scores across visit numbers, separated by clinical group.\n",
    "4.  **Individual Examples:** Plot the MMSE trajectories for a few example subjects to visualize individual variability (spaghetti plot).\n",
    "Plots and relevant statistics are logged to W&B and saved locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43af97d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Performing Deeper Longitudinal Analysis ---\")\n",
    "\n",
    "# Calculate Time Between Visits (assuming 'Visit' column indicates order and 'Age' reflects age at visit)\n",
    "# More robust: Use 'Days_from_Baseline' if available, otherwise calculate from Age, assuming visits are sorted.\n",
    "# Let's assume we need to calculate from Age and Visit number.\n",
    "print(\"Calculating time intervals between visits...\")\n",
    "clinical_df_sorted = clinical_df.sort_values(by=['Subject ID', 'Visit'])\n",
    "# Calculate difference in Age between consecutive visits for the same subject\n",
    "clinical_df_sorted['Age_Diff'] = clinical_df_sorted.groupby('Subject ID')['Age'].diff()\n",
    "# Estimate years between visits (might be noisy if birthdays fall between visits)\n",
    "# A dedicated Days_from_Baseline column is usually better if present.\n",
    "clinical_df_sorted['Years_Since_Prev_Visit'] = clinical_df_sorted['Age_Diff'] # Approximation\n",
    "\n",
    "# Handle the first visit (NaN difference)\n",
    "first_visit_mask = clinical_df_sorted['Visit'] == 1\n",
    "clinical_df_sorted.loc[first_visit_mask, 'Years_Since_Prev_Visit'] = 0\n",
    "\n",
    "# Analyze distribution of intervals (excluding first visit)\n",
    "visit_intervals = clinical_df_sorted[clinical_df_sorted['Visit'] > 1]['Years_Since_Prev_Visit'].dropna()\n",
    "\n",
    "if not visit_intervals.empty:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    sns.histplot(visit_intervals, kde=True, bins=20, ax=ax)\n",
    "    ax.set_title('Distribution of Approximate Years Between Consecutive Visits')\n",
    "    ax.set_xlabel('Approx. Years Since Previous Visit')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    finalize_plot(fig, run, \"charts/longitudinal/visit_interval_distribution\", output_dir / 'visit_interval_distribution.png')\n",
    "\n",
    "    interval_stats = visit_intervals.describe()\n",
    "    print(\"\\nApproximate Visit Interval Stats (Years):\")\n",
    "    print(interval_stats)\n",
    "    if run:\n",
    "        run.log({f'stats/visit_interval_{k}': v for k, v in interval_stats.items()})\n",
    "else:\n",
    "    print(\"\\nCould not calculate meaningful visit intervals (e.g., only single visits).\")\n",
    "\n",
    "# --- Baseline Analysis (Visit == 1) ---\n",
    "print(\"\\nAnalyzing Baseline Characteristics (Visit == 1)...\")\n",
    "baseline_df = clinical_df[clinical_df['Visit'] == 1].copy() # Use copy to avoid SettingWithCopyWarning\n",
    "\n",
    "if not baseline_df.empty:\n",
    "    print(f\"Number of subjects at baseline (Visit 1): {baseline_df['Subject ID'].nunique()}\")\n",
    "    if run: run.log({'dataset/num_subjects_baseline': baseline_df['Subject ID'].nunique()})\n",
    "\n",
    "    # Baseline Group Distribution\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    baseline_group_order = baseline_df['Group'].value_counts().index\n",
    "    sns.countplot(data=baseline_df, x='Group', order=baseline_group_order, ax=ax)\n",
    "    ax.set_title('Distribution of Clinical Groups at Baseline (Visit 1)')\n",
    "    ax.set_xlabel('Group at Visit 1')\n",
    "    ax.set_ylabel('Number of Subjects')\n",
    "    finalize_plot(fig, run, \"charts/baseline/group_distribution\", output_dir / 'baseline_group_distribution.png')\n",
    "\n",
    "    # Baseline MMSE by Group\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.boxplot(data=baseline_df, x='Group', y='MMSE', order=group_order_analysis, ax=ax)\n",
    "    ax.set_title('MMSE Scores at Baseline (Visit 1) by Group')\n",
    "    ax.set_xlabel('Clinical Group at Visit 1')\n",
    "    ax.set_ylabel('MMSE Score')\n",
    "    finalize_plot(fig, run, \"charts/baseline/mmse_boxplot\", output_dir / 'baseline_mmse_boxplot.png')\n",
    "\n",
    "    # Baseline Age by Group\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.violinplot(data=baseline_df, x='Group', y='Age', order=group_order_analysis, ax=ax)\n",
    "    ax.set_title('Age Distribution at Baseline (Visit 1) by Group')\n",
    "    ax.set_xlabel('Clinical Group at Visit 1')\n",
    "    ax.set_ylabel('Age (Years)')\n",
    "    finalize_plot(fig, run, \"charts/baseline/age_violinplot\", output_dir / 'baseline_age_violinplot.png')\n",
    "\n",
    "else:\n",
    "    print(\"No data found for Visit == 1.\")\n",
    "\n",
    "\n",
    "# --- Average MMSE/nWBV Trends ---\n",
    "print(\"\\nPlotting Average Trends Over Visits...\")\n",
    "# Average MMSE score change over visits, separated by group\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.lineplot(data=clinical_df.dropna(subset=['MMSE']), x='Visit', y='MMSE', hue='Group', marker='o', errorbar='sd', ax=ax, hue_order=group_order_analysis) # Show standard deviation\n",
    "ax.set_title('Average MMSE Score Trend over Visits by Group')\n",
    "ax.set_xlabel('Visit Number')\n",
    "ax.set_ylabel('Average MMSE Score')\n",
    "ax.set_xticks(sorted(clinical_df['Visit'].unique())) # Ensure all visit numbers are shown as ticks\n",
    "finalize_plot(fig, run, \"charts/longitudinal/mmse_trend_by_visit_group\", output_dir / 'mmse_trend_by_visit_group.png')\n",
    "\n",
    "# Average nWBV change over visits, separated by group\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.lineplot(data=clinical_df.dropna(subset=['nWBV']), x='Visit', y='nWBV', hue='Group', marker='o', errorbar='sd', ax=ax, hue_order=group_order_analysis)\n",
    "ax.set_title('Average nWBV Trend over Visits by Group')\n",
    "ax.set_xlabel('Visit Number')\n",
    "ax.set_ylabel('Average nWBV')\n",
    "ax.set_xticks(sorted(clinical_df['Visit'].unique()))\n",
    "finalize_plot(fig, run, \"charts/longitudinal/nwbv_trend_by_visit_group\", output_dir / 'nwbv_trend_by_visit_group.png')\n",
    "\n",
    "# Example Individual Subject Plot\n",
    "example_subjects = []\n",
    "# Ensure groups exist before trying to sample from them\n",
    "present_groups = clinical_df['Group'].unique()\n",
    "for grp in present_groups:\n",
    "    subjects_in_group = clinical_df[clinical_df['Group'] == grp]['Subject ID'].unique()\n",
    "    example_subjects.extend(subjects_in_group[:3]) # Take first 3 available subjects\n",
    "\n",
    "if example_subjects:\n",
    "    example_df = clinical_df[clinical_df['Subject ID'].isin(example_subjects)].copy() # Use copy\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    sns.lineplot(data=example_df.dropna(subset=['MMSE']),\n",
    "                 x='Visit', y='MMSE', hue='Subject ID', style='Group', marker='o', ax=ax)\n",
    "    ax.set_title('Individual MMSE Score Trends for Example Subjects')\n",
    "    ax.set_xlabel('Visit Number')\n",
    "    ax.set_ylabel('MMSE Score')\n",
    "    ax.set_xticks(sorted(example_df['Visit'].unique()))\n",
    "    # Adjust legend positioning\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles=handles, labels=labels, title=\"Subject (Style=Group)\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    fig.tight_layout(rect=[0, 0, 0.85, 1]) # Adjust layout to make space for legend outside\n",
    "    finalize_plot(fig, run, \"charts/longitudinal/mmse_individual_trends_example\", output_dir / 'mmse_individual_trends_example.png')\n",
    "else:\n",
    "    print(\"Could not generate example individual subject plot (no subjects found).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c453332a",
   "metadata": {},
   "source": [
    "## Verify MRI Scan File Availability\n",
    "\n",
    "Iterate through each visit record in the loaded clinical data (`clinical_df_raw`). For each record:\n",
    "1.  Construct the expected file path(s) for the raw T1w MPRAGE scan data (specifically looking for `.nifti.img` and `.nifti.hdr` pairs within the `RAW` subfolder of the directory named by `MRI ID`, checking across the base paths defined in `config.json`).\n",
    "2.  Check if the expected folder and both files (`.img` + `.hdr`) actually exist in the local filesystem.\n",
    "3.  Record the verification status (folder found, number of valid pairs found) for each `MRI ID`.\n",
    "\n",
    "NOTE ON MULTIPLE MPRAGE SCANS PER SESSION: The OASIS documentation notes that 3-4 individual T1w MPRAGE scans were typically acquired during each imaging session. Our check for sessions with >= 3 pairs helps confirm we are finding data consistent with this expected acquisition protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf0b5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- Verifying Local MPRAGE Files (.img + .hdr) in specified base paths ---\")\n",
    "print(f\"Expecting structure like: <base_path>/<MRI ID>/RAW/mpr-<#>.nifti.{{img,hdr}}\")\n",
    "\n",
    "# Check if *at least one* base path exists\n",
    "any_base_path_exists = any(p.is_dir() for p in MRI_BASE_PATHS)\n",
    "if not any_base_path_exists:\n",
    "    print(f\"Error: None of the base MRI paths {[str(p) for p in MRI_BASE_PATHS]} exist or are directories.\")\n",
    "    print(\"Skipping image file verification.\")\n",
    "    if run:\n",
    "        run.log({'verification/any_mri_base_path_exists': False, 'config/checked_mri_paths': [str(p) for p in MRI_BASE_PATHS]})\n",
    "        run.finish()\n",
    "    exit()\n",
    "else:\n",
    "    if run: run.log({'verification/any_mri_base_path_exists': True})\n",
    "\n",
    "# Initialize counters and storage for W&B table\n",
    "mri_ids_processed = 0\n",
    "folders_missing = 0\n",
    "folders_found = 0\n",
    "mprs_found_total = 0\n",
    "subjects_with_any_mprs = set()\n",
    "subjects_with_three_or_more_mprs = set()\n",
    "verification_log_entries = [] # Store detailed results for W&B Table\n",
    "\n",
    "print(\"Starting scan verification...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# --- Loop and Verify using Helper Function ---\n",
    "for index, row in clinical_df.iterrows():\n",
    "    log_entry = verify_scan_files(row, MRI_BASE_PATHS, MPR_IMG_PATTERN)\n",
    "    verification_log_entries.append(log_entry)\n",
    "\n",
    "    # Update summary stats based on the result\n",
    "    mri_ids_processed += 1\n",
    "    if not log_entry['mri_folder_exists']:\n",
    "        folders_missing += 1\n",
    "        potential_paths_str = \", \".join([str(p / row['MRI ID'] / 'RAW') for p in MRI_BASE_PATHS])\n",
    "        print(f\"[{index+1}/{len(clinical_df)}] [Missing Folder] MRI ID {log_entry['mri_id']} ({log_entry['subject_id']}): Expected folder not found. Searched: {potential_paths_str}\")\n",
    "    else:\n",
    "        folders_found += 1\n",
    "        num_found = log_entry['mprs_found_count']\n",
    "        mprs_found_total += num_found\n",
    "        if num_found > 0:\n",
    "            subjects_with_any_mprs.add(log_entry['subject_id'])\n",
    "            if num_found >= 3:\n",
    "                subjects_with_three_or_more_mprs.add(log_entry['subject_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9380171",
   "metadata": {},
   "source": [
    "## Final Verification Summary, Logging, and Output Saving\n",
    "\n",
    "Summarize the results of the MRI file verification (number of IDs processed, folders found/missing, total pairs found, subject counts meeting criteria). Log these summary statistics and the detailed per-scan verification results (as a `wandb.Table`) to Weights & Biases. Save the detailed verification results DataFrame (`verification_df`) locally as `verification_details.csv` for use in the next notebook. Also, log the list of missing folders as a W&B artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23141487",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "verification_duration = end_time - start_time\n",
    "print(f\"\\nFinished scan verification in {verification_duration:.2f} seconds.\")\n",
    "\n",
    "\n",
    "print(\"Processing verification results...\")\n",
    "verification_df = pd.DataFrame(verification_log_entries)\n",
    "\n",
    "# Calculate Final Summary Statistics (using the DataFrame)\n",
    "mri_ids_processed = len(verification_df)\n",
    "folders_found = 0\n",
    "mprs_found_total = 0\n",
    "subjects_with_any_mprs = set()\n",
    "subjects_with_three_or_more_mprs = set()\n",
    "\n",
    "if not verification_df.empty:\n",
    "    folders_found = verification_df['mri_folder_exists'].sum()\n",
    "    mprs_found_total = verification_df['mprs_found_count'].sum()\n",
    "    subjects_with_any_mprs = set(verification_df[verification_df['mprs_found_count'] > 0]['subject_id'].unique())\n",
    "    subjects_with_three_or_more_mprs = set(verification_df[verification_df['found_three_or_more_mprs'] == True]['subject_id'].unique())\n",
    "else:\n",
    "    print(\"Note: Verification DataFrame is empty (no entries processed).\")\n",
    "\n",
    "folders_missing = mri_ids_processed - folders_found\n",
    "any_subject_with_all_mprs = len(subjects_with_three_or_more_mprs) > 0 \n",
    "\n",
    "print(\"\\n--- Final Verification Summary ---\")\n",
    "print(f\"Total MRI IDs processed: {mri_ids_processed}\")\n",
    "print(f\"Expected folders found: {folders_found}\")\n",
    "print(f\"Expected folders missing: {folders_missing}\")\n",
    "print(f\"Total complete MPR pairs (.img + .hdr) found: {mprs_found_total}\")\n",
    "print(f\"Unique subjects with >= 1 MPR pair found: {len(subjects_with_any_mprs)}\")\n",
    "print(f\"Unique subjects with >= 1 scan having >= 3 MPR pairs: {len(subjects_with_three_or_more_mprs)}\")\n",
    "\n",
    "verification_output_path = output_dir / \"verification_details.csv\"\n",
    "try:\n",
    "    # Use index=False to avoid writing the default DataFrame index\n",
    "    verification_df.to_csv(verification_output_path, index=False)\n",
    "    print(f\"\\nDetailed verification results saved locally to: {verification_output_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not save verification details locally. Error: {e}\")\n",
    "    \n",
    "if folders_missing > 0:\n",
    "     print(f\"⚠️ Warning: {folders_missing} expected MRI folders were not found.\")\n",
    "if not any_subject_with_all_mprs:\n",
    "    print(\"⚠️ Warning: No single MRI scan session was found containing 3 or more valid MPR pairs.\")\n",
    "\n",
    "\n",
    "if run:\n",
    "    print(\"\\nLogging verification results to W&B...\")\n",
    "    # Log summary stats\n",
    "    run.log({\n",
    "        'verification/duration_seconds': verification_duration,\n",
    "        'verification/total_mri_ids_processed': mri_ids_processed,\n",
    "        'verification/mri_folders_found': folders_found,\n",
    "        'verification/mri_folders_missing': folders_missing,\n",
    "        'verification/total_mpr_pairs_found': mprs_found_total,\n",
    "        'verification/unique_subjects_with_any_mprs': len(subjects_with_any_mprs),\n",
    "        'verification/unique_subjects_with_three_or_more_mprs': len(subjects_with_three_or_more_mprs),\n",
    "    })\n",
    "\n",
    "    # Log detailed table\n",
    "    if not verification_df.empty:\n",
    "        verification_table = wandb.Table(dataframe=verification_df)\n",
    "        run.log({\"verification/details_per_scan\": verification_table})\n",
    "        print(\"Detailed verification results logged as W&B Table.\")\n",
    "    else:\n",
    "        print(\"Skipping detailed table logging as verification DataFrame is empty.\")\n",
    "\n",
    "    # Log missing files list as artifact\n",
    "    missing_folders_df = verification_df[~verification_df['mri_folder_exists']][['mri_id', 'subject_id', 'visit']]\n",
    "    if not missing_folders_df.empty:\n",
    "         missing_file_path = output_dir / \"missing_mri_folders.csv\"\n",
    "         try:\n",
    "             missing_folders_df.to_csv(missing_file_path, index=False)\n",
    "             missing_artifact = wandb.Artifact(\"missing_mri_folders\", type=\"analysis_output\",\n",
    "                                              description=\"List of MRI IDs whose scan folders were not found.\")\n",
    "             missing_artifact.add_file(str(missing_file_path))\n",
    "             run.log_artifact(missing_artifact)\n",
    "             print(f\"List of {len(missing_folders_df)} missing folders logged as W&B Artifact and saved locally.\")\n",
    "         except Exception as e:\n",
    "             print(f\"Warning: Could not save/log missing folders list. Error: {e}\")\n",
    "    else:\n",
    "         print(\"No missing MRI folders found to log/save.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7c717b",
   "metadata": {},
   "source": [
    "## Finalize Run\n",
    "\n",
    "Complete the execution for this notebook and finish the associated Weights & Biases run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750c8968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Finish W&B Run ---\n",
    "print(\"\\n--- Exploration and Verification complete. Finishing W&B run. ---\")\n",
    "if run:\n",
    "    run.finish()\n",
    "    print(\"W&B run finished.\")\n",
    "else:\n",
    "    print(\"No active W&B run to finish.\")\n",
    "\n",
    "print(\"\\nScript execution finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro_pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
