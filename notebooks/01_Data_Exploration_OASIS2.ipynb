{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f0d52f0",
   "metadata": {},
   "source": [
    "# Notebook 01: OASIS-2 Dataset - Initial Exploration & MRI File Verification\n",
    "\n",
    "**Project Phase:** 1 (Data Ingestion, Exploration, and Validation)\n",
    "**Dataset:** OASIS-2 Longitudinal MRI & Clinical Data\n",
    "\n",
    "**Purpose:**\n",
    "This notebook serves as the initial step in the OASIS-2 data processing pipeline. Its primary objectives are:\n",
    "1.  Load the raw OASIS-2 longitudinal clinical and demographic data from the specified Excel file.\n",
    "2.  Perform a comprehensive exploratory data analysis to understand data structure, variable types, distributions, missing values, and basic relationships between key variables.\n",
    "3.  Verify the local file system presence of raw T1w MPRAGE scan files (`.img` + `.hdr` pairs) corresponding to entries in the clinical data, based on paths defined in `config.json`.\n",
    "4.  Log summary statistics, generated plots, and the detailed MRI scan verification results to Weights & Biases (W&B) for experiment tracking and reproducibility.\n",
    "5.  Save key outputs locally, notably `verification_details.csv`, which lists the status of each scan file and will be used in subsequent pipeline stages.\n",
    "\n",
    "**Workflow:**\n",
    "1.  **Setup:** Import libraries, configure `sys.path` to access `src/` utilities, and load the main project configuration (`config.json`).\n",
    "2.  **W&B Initialization:** Start a new W&B run for this data exploration task using the `initialize_wandb_run` utility. Define a general output directory for this notebook's local saves.\n",
    "3.  **Load Clinical Data:** Load the OASIS-2 clinical data Excel file. Log the raw dataset table as a W&B artifact.\n",
    "4.  **Initial Data Inspection:** Examine DataFrame info, descriptive statistics, and missing value patterns. Log summaries to W&B and save tables locally.\n",
    "5.  **Variable Distribution Analysis:** Visualize distributions of key variables (Age, MMSE, nWBV, Group, Gender, Visits per Subject) using histograms and count plots. Log plots to W&B and save locally.\n",
    "6.  **Relationship Analysis:** Explore pairwise relationships (e.g., Age vs. MMSE) using scatter plots. Visualize and log a correlation matrix.\n",
    "7.  **Group-wise Analysis:** Compare variable distributions across clinical groups.\n",
    "8.  **Longitudinal Aspect Exploration:** Analyze visit intervals, baseline cohort characteristics, and plot average trends and example individual trajectories for key scores.\n",
    "9.  **MRI Scan File Verification:** Iterate through clinical records, check for corresponding raw MRI files (`.img`/`.hdr`) based on expected directory structure, and log verification status.\n",
    "10. **Summarize & Save Verification Outputs:** Compile verification results into a DataFrame, save `verification_details.csv` and `missing_mri_folders.csv` (if any) locally. Log these as a W&B Table and Artifacts.\n",
    "11. **Finalize W&B Run.**\n",
    "\n",
    "**Input:**\n",
    "* `config.json`: Main project configuration file (specifies paths, W&B details, etc.).\n",
    "* OASIS-2 Clinical Data Excel file (path specified in `config.json`).\n",
    "* Local directories containing raw OASIS-2 MRI scans (paths specified in `config.json`).\n",
    "\n",
    "**Output:**\n",
    "* **Local Files (in notebook-specific output directory, e.g., `notebooks/outputs/01_Data_Exploration_OASIS2/`):**\n",
    "    * `descriptive_stats.csv`\n",
    "    * `missing_values_summary.csv`\n",
    "    * `verification_details.csv` (Key input for Notebook 02 & MRI preprocessing scripts)\n",
    "    * `missing_mri_folders.csv` (If applicable)\n",
    "    * Plots as PNG files.\n",
    "* **W&B Run:**\n",
    "    * Logged run configuration (including paths used by this notebook).\n",
    "    * Summary statistics of the dataset.\n",
    "    * All generated EDA plots as `wandb.Image`.\n",
    "    * `verification_details.csv` as a `wandb.Table`.\n",
    "    * Raw clinical data table (`INPUT_DATA_PATH`) and `missing_mri_folders.csv` as W&B Artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c931943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In: notebooks/01_Data_Exploration_OASIS2.ipynb\n",
    "# Purpose: Load OASIS-2 clinical data using config, perform detailed exploration\n",
    "#          (including longitudinal aspects), verify MPRAGE file presence,\n",
    "#          log results efficiently to W&B, and save key outputs locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ae22bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Import Libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdeb501",
   "metadata": {},
   "source": [
    "## 1. Setup: Project Configuration and Paths\n",
    "\n",
    "This section handles the initial setup for the notebook:\n",
    "* Determines the project's root directory.\n",
    "* Adds the `src` directory (containing custom utility modules) to the Python system path to allow imports.\n",
    "* Imports necessary custom utility functions.\n",
    "* Loads the main project configuration from `config.json`.\n",
    "* Defines key dataset identifiers and notebook-specific parameters.\n",
    "* Resolves and prints essential input paths for clinical data and MRI base directories, and sets up the primary output directory for this notebook's locally saved files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956cd396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Project Setup, Configuration Loading, and Utility Imports ---\n",
    "print(\"--- Initializing Project Setup & Configuration ---\")\n",
    "\n",
    "# Initialize\n",
    "PROJECT_ROOT = None\n",
    "base_config = {}\n",
    "\n",
    "try:\n",
    "    # Determine project root assuming this notebook is in a 'notebooks' subdirectory\n",
    "    current_notebook_path = Path.cwd() \n",
    "    potential_project_root = current_notebook_path.parent \n",
    "    if (potential_project_root / \"src\").is_dir() and (potential_project_root / \"config.json\").is_file():\n",
    "        PROJECT_ROOT = potential_project_root\n",
    "    else: # Fallback: assume current working directory IS the project root\n",
    "        PROJECT_ROOT = current_notebook_path\n",
    "    \n",
    "    if not (PROJECT_ROOT / \"src\").is_dir() or not (PROJECT_ROOT / \"config.json\").is_file():\n",
    "        raise FileNotFoundError(f\"Could not reliably find 'src' directory or 'config.json'. \"\n",
    "                                f\"PROJECT_ROOT determined as: {PROJECT_ROOT}. \"\n",
    "                                \"Ensure 'config.json' is at the project root and 'src' dir exists.\")\n",
    "\n",
    "    if str(PROJECT_ROOT) not in sys.path:\n",
    "        sys.path.insert(0, str(PROJECT_ROOT)) # Add project root to path for src imports\n",
    "    print(f\"PROJECT_ROOT: {PROJECT_ROOT}\")\n",
    "    print(f\"Added '{str(PROJECT_ROOT)}' to sys.path for src imports.\")\n",
    "\n",
    "    # Import custom utilities AFTER path setup\n",
    "    from src.wandb_utils import initialize_wandb_run \n",
    "    from src.plotting_utils import finalize_plot\n",
    "    print(\"Successfully imported custom utilities.\")\n",
    "\n",
    "except FileNotFoundError as e_path:\n",
    "    print(f\"CRITICAL ERROR in project setup (paths or src): {e_path}\")\n",
    "    # exit() # Or raise error to stop notebook\n",
    "except ImportError as e_imp:\n",
    "    print(f\"CRITICAL ERROR: Could not import custom utilities: {e_imp}\")\n",
    "    print(\"Ensure src/wandb_utils.py (and other required utils) exist and are error-free.\")\n",
    "    # exit()\n",
    "except Exception as e_general_setup:\n",
    "    print(f\"CRITICAL ERROR during initial setup: {e_general_setup}\")\n",
    "    # exit()\n",
    "\n",
    "\n",
    "# --- Load Main Project Configuration ---\n",
    "print(\"\\n--- Loading Main Project Configuration from config.json ---\")\n",
    "try:\n",
    "    if PROJECT_ROOT is None: # Should have been caught above, but as a safeguard\n",
    "        raise ValueError(\"PROJECT_ROOT was not successfully defined. Cannot load configuration.\")\n",
    "    CONFIG_PATH_MAIN = PROJECT_ROOT / 'config.json'\n",
    "    with open(CONFIG_PATH_MAIN, 'r', encoding='utf-8') as f:\n",
    "        base_config = json.load(f)\n",
    "    print(f\"Main project config loaded successfully from: {CONFIG_PATH_MAIN}\")\n",
    "except Exception as e_cfg:\n",
    "    print(f\"CRITICAL ERROR loading main config.json: {e_cfg}\")\n",
    "    # exit() \n",
    "\n",
    "# --- Define Dataset, Notebook Specifics, and Key Paths ---\n",
    "# These are based on the loaded base_config.\n",
    "DATASET_IDENTIFIER = \"oasis2\" # Specific to this notebook's focus\n",
    "NOTEBOOK_MODULE_NAME = \"01_Data_Exploration\" # For naming outputs and W&B job type\n",
    "\n",
    "# Initialize paths to None or empty lists for safety before assignment\n",
    "INPUT_DATA_PATH = None\n",
    "MRI_BASE_PATHS_CONFIG_RELATIVE = []\n",
    "MRI_BASE_PATHS_ABSOLUTE = []\n",
    "MPR_IMG_PATTERN_CONFIG = None\n",
    "output_dir = None # This will be the static output dir for NB01\n",
    "\n",
    "try:\n",
    "    if not base_config: # Check if base_config loaded\n",
    "        raise ValueError(\"base_config is empty or not loaded. Cannot define paths.\")\n",
    "\n",
    "    # Resolve input paths from base_config\n",
    "    INPUT_DATA_PATH = PROJECT_ROOT / base_config['data']['clinical_excel_path']\n",
    "    MRI_BASE_PATHS_CONFIG_RELATIVE = base_config['data'].get('mri_base_paths', [])\n",
    "    MRI_BASE_PATHS_ABSOLUTE = [PROJECT_ROOT / p for p in MRI_BASE_PATHS_CONFIG_RELATIVE]\n",
    "    MPR_IMG_PATTERN_CONFIG = re.compile(base_config['mri_verification']['mpr_img_pattern'])\n",
    "\n",
    "    # Define the main output directory for THIS notebook (static, not W&B run-specific subfolder)\n",
    "    output_dir_base_from_config = PROJECT_ROOT / base_config['data']['output_dir_base']\n",
    "    output_dir = output_dir_base_from_config / f\"{NOTEBOOK_MODULE_NAME}_{DATASET_IDENTIFIER}\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True) # Create if it doesn't exist\n",
    "\n",
    "    print(f\"\\nKey paths defined:\")\n",
    "    print(f\"  Input clinical data: {INPUT_DATA_PATH}\")\n",
    "    print(f\"  MRI base paths: {[str(p) for p in MRI_BASE_PATHS_ABSOLUTE]}\")\n",
    "    print(f\"  Notebook output directory (local saves): {output_dir}\")\n",
    "\n",
    "except KeyError as e_key:\n",
    "    print(f\"CRITICAL ERROR: Missing key {e_key} in base_config needed for path definitions.\")\n",
    "    # exit()\n",
    "except Exception as e_paths:\n",
    "    print(f\"CRITICAL ERROR defining paths: {e_paths}\")\n",
    "    # exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a6cb77",
   "metadata": {},
   "source": [
    "## 2. Helper Function\n",
    "\n",
    "Define helper function used within this notebook for verifying MRI scan file presence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c4fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Function ---\n",
    "print(\"\\n--- Defining Helper Function ---\")\n",
    "\n",
    "# --- verify_scan_files function ---\n",
    "# Ensure it uses the mri_base_paths_absolute and mpr_img_pattern_config defined above when called\n",
    "def verify_scan_files(row: pd.Series, \n",
    "                      abs_mri_base_paths: list[Path], \n",
    "                      mpr_pattern: re.Pattern) -> dict:\n",
    "    \"\"\"\n",
    "    Verifies presence of Analyze 7.5 .img/.hdr pairs for a given clinical data row\n",
    "    by checking expected file structures within the provided MRI base paths.\n",
    "\n",
    "    Args:\n",
    "        row (pd.Series): A row from the clinical DataFrame, expected to contain\n",
    "                         'Subject ID' and 'MRI ID'. Optional: 'Visit', 'Group'.\n",
    "        abs_mri_base_paths (list[Path]): List of absolute Path objects for MRI base directories.\n",
    "        mpr_pattern (re.Pattern): Compiled regex pattern to match MPRAGE .img filenames\n",
    "                                  (e.g., to extract \"mpr-1\", \"mpr-2\").\n",
    "\n",
    "    Returns:\n",
    "        dict: A log entry dictionary with verification details for the MRI ID in the row,\n",
    "              including 'mri_folder_exists', 'mprs_found_count', 'mpr_labels_found', etc.\n",
    "    \"\"\"\n",
    "    subject_id = row['Subject ID']\n",
    "    mri_id = row['MRI ID'] # This is the MRI Session ID\n",
    "    mri_scan_folder_path = None # Path object to the specific .../<MRI ID>/RAW/ folder\n",
    "    base_path_where_found = None # Which of the MRI_BASE_PATHS it was found under\n",
    "\n",
    "    # Prepare initial log entry\n",
    "    log_details = {\n",
    "        'mri_id': mri_id,\n",
    "        'subject_id': subject_id,\n",
    "        'visit': row.get('Visit'), \n",
    "        'group': row.get('Group'),\n",
    "        'mri_base_path_used': None,\n",
    "        'mri_folder_path_checked': None, # For logging which exact folder was checked\n",
    "        'mri_folder_exists': False,\n",
    "        # 'mri_folder_is_dir' field removed as exists + is_dir check is implicit if folder_path is set\n",
    "        'mprs_found_count': 0,\n",
    "        'mpr_labels_found': [], # e.g., ['mpr-1', 'mpr-2']\n",
    "        'found_three_or_more_mprs': False,\n",
    "        'error_listing_dir': None # Store any OSError during directory listing\n",
    "    }\n",
    "\n",
    "    # Search for the specific MRI ID's RAW folder across the provided base paths\n",
    "    for current_mri_base_path in abs_mri_base_paths:\n",
    "        potential_folder = current_mri_base_path / mri_id / 'RAW'\n",
    "        log_details['mri_folder_path_checked'] = str(potential_folder) # Log path being checked\n",
    "        if potential_folder.is_dir():\n",
    "            mri_scan_folder_path = potential_folder\n",
    "            base_path_where_found = str(current_mri_base_path)\n",
    "            break \n",
    "    \n",
    "    log_details['mri_base_path_used'] = base_path_where_found\n",
    "\n",
    "    if mri_scan_folder_path is None:\n",
    "        # mri_folder_exists remains False, other counts remain 0/empty\n",
    "        return log_details\n",
    "\n",
    "    log_details['mri_folder_exists'] = True\n",
    "    \n",
    "    found_mpr_scan_pairs = {} # Stores {label: (img_path, hdr_path)}\n",
    "    try:\n",
    "        # Iterate through files in the .../<MRI ID>/RAW/ directory\n",
    "        for file_item in mri_scan_folder_path.iterdir():\n",
    "            match_result = mpr_pattern.match(file_item.name)\n",
    "            if match_result: # If filename matches the MPRAGE .img pattern\n",
    "                mpr_label_found = match_result.group(1) # Extracts \"mpr-X\"\n",
    "                # Construct corresponding .hdr filename path and check for its existence\n",
    "                hdr_file_path = file_item.with_name(f\"{mpr_label_found}.nifti.hdr\")\n",
    "                if hdr_file_path.is_file(): # Check if the .hdr pair exists\n",
    "                    found_mpr_scan_pairs[mpr_label_found] = (str(file_item), str(hdr_file_path))\n",
    "    except OSError as e_os:\n",
    "        log_details['error_listing_dir'] = str(e_os) # Log error if directory listing fails\n",
    "        return log_details # Return early as we can't proceed with this scan\n",
    "\n",
    "    num_valid_pairs_found = len(found_mpr_scan_pairs)\n",
    "    log_details.update({\n",
    "        'mprs_found_count': num_valid_pairs_found,\n",
    "        'mpr_labels_found': sorted(list(found_mpr_scan_pairs.keys())),\n",
    "        'found_three_or_more_mprs': num_valid_pairs_found >= 3\n",
    "    })\n",
    "    return log_details\n",
    "\n",
    "print(\"Helper function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70644f",
   "metadata": {},
   "source": [
    "## 3. Initialize Weights & Biases Run\n",
    "\n",
    "A new W&B run is initialized for this data exploration and MRI verification notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5f2c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialize W&B Run ---\n",
    "print(\"\\n--- Initializing Weights & Biases Run for Notebook 01 ---\")\n",
    "\n",
    "# Configuration specific to this NB01 run to be logged to W&B\n",
    "# Using resolved absolute paths for clarity in W&B logs where appropriate,\n",
    "# and relative (from config) for others to show what was configured.\n",
    "nb01_run_config_for_wandb = {\n",
    "    \"notebook_name_code\": f\"{NOTEBOOK_MODULE_NAME}_{DATASET_IDENTIFIER}\", # e.g., 01_Data_Exploration_oasis2\n",
    "    \"dataset_source\": DATASET_IDENTIFIER,\n",
    "    \"input_clinical_data_path_actual\": str(INPUT_DATA_PATH), # Actual path used\n",
    "    \"mri_base_paths_configured\": MRI_BASE_PATHS_CONFIG_RELATIVE, # What was in config\n",
    "    \"mpr_img_pattern_configured\": MPR_IMG_PATTERN_CONFIG.pattern, # Regex pattern used\n",
    "    \"output_dir_for_local_saves\": str(output_dir), # Static output dir for this notebook\n",
    "    \"execution_timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "}\n",
    "\n",
    "# Initialize W&B run using the utility from src/wandb_utils.py\n",
    "# The 'run' object will be global for this notebook if successful\n",
    "run = initialize_wandb_run(\n",
    "    base_project_config=base_config, # Contains WANDB_ENTITY and WANDB_PROJECT\n",
    "    job_group=\"DataProcessing\",       # Broad category for this type of notebook\n",
    "    job_specific_type=f\"ExploreValidate-{DATASET_IDENTIFIER}\", \n",
    "    run_specific_config=nb01_run_config_for_wandb, # Config dict for this specific run\n",
    "    custom_run_name_elements=[\"EDA\"], # Keeps run name concise and informative\n",
    "    notes=f\"{DATASET_IDENTIFIER.upper()}: Data exploration, EDA, and raw MRI file verification.\"\n",
    ")\n",
    "\n",
    "if run:\n",
    "    print(f\"W&B run '{run.name}' (Job Type: '{run.job_type}') initialized. View at: {run.url}\")\n",
    "    # Note: output_dir is already defined and created in Cell 3 for this notebook's static outputs.\n",
    "    # No need to use get_notebook_run_output_dir here if NB01 uses a fixed output_dir.\n",
    "else:\n",
    "    print(\"Proceeding without W&B logging for this session (W&B run initialization failed).\")\n",
    "    # output_dir should still be defined from Cell 3 for local saves even if W&B fails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7a204f",
   "metadata": {},
   "source": [
    "## Load Clinical Data\n",
    "\n",
    "Load the raw longitudinal clinical and demographic data from the specified Excel file using pandas. We also initialize Weights & Biases here to track this exploration run and log the source data as an artifact for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736fde7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Clinical Data ---\n",
    "print(f\"\\n--- Loading Clinical Data from: {INPUT_DATA_PATH} ---\")\n",
    "clinical_df = None # Initialize\n",
    "try:\n",
    "    if INPUT_DATA_PATH is None or not INPUT_DATA_PATH.is_file(): # Check if path was defined and exists\n",
    "         raise FileNotFoundError(f\"Input data file not found or path not defined: {INPUT_DATA_PATH}\")\n",
    "\n",
    "    clinical_df = pd.read_excel(INPUT_DATA_PATH)\n",
    "    print(f\"Raw clinical data loaded successfully. Shape: {clinical_df.shape}\")\n",
    "\n",
    "    if clinical_df.empty:\n",
    "        print(\"CRITICAL ERROR: Loaded clinical dataframe is empty.\")\n",
    "        if run: run.finish(exit_code=1) # Finish W&B run with error status\n",
    "\n",
    "    # Log initial dataset characteristics to W&B run if active\n",
    "    if run:\n",
    "        run.log({'dataset_raw/num_rows': clinical_df.shape[0],\n",
    "                 'dataset_raw/num_columns': clinical_df.shape[1]})\n",
    "        \n",
    "        # Log a preview of the raw data table as a W&B artifact\n",
    "        print(\"Logging raw clinical data table as W&B artifact...\")\n",
    "        # Use a more descriptive artifact name, incorporating dataset identifier\n",
    "        raw_data_artifact_name = f\"raw_clinical_data_{DATASET_IDENTIFIER}\"\n",
    "        raw_data_artifact_description = (\n",
    "            f\"Raw clinical and demographic data for the {DATASET_IDENTIFIER} dataset, \"\n",
    "            f\"loaded from {INPUT_DATA_PATH.name}.\"\n",
    "        )\n",
    "        raw_data_table_artifact = wandb.Artifact(\n",
    "            raw_data_artifact_name, \n",
    "            type=f\"raw-dataset\", # Consistent type for raw datasets\n",
    "            description=raw_data_artifact_description,\n",
    "            metadata={\"source_file\": str(INPUT_DATA_PATH), \n",
    "                      \"shape\": list(clinical_df.shape),\n",
    "                      \"load_timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "        )\n",
    "        # Add the actual data file to the artifact for full reproducibility\n",
    "        raw_data_table_artifact.add_file(str(INPUT_DATA_PATH), name=\"source_excel_file.xlsx\")\n",
    "        \n",
    "        # Add a sample of the table directly for quick preview in W&B UI\n",
    "        raw_data_wandb_table = wandb.Table(dataframe=clinical_df.head(100)) # Log first 100 rows\n",
    "        raw_data_table_artifact.add(raw_data_wandb_table, name=\"raw_data_preview\")\n",
    "        \n",
    "        run.log_artifact(raw_data_table_artifact, aliases=[\"initial_load\", f\"{time.strftime('%Y%m%d')}\"])\n",
    "        print(f\"Raw data artifact '{raw_data_artifact_name}' logged to W&B.\")\n",
    "\n",
    "except FileNotFoundError as e_fnf:\n",
    "    print(f\"CRITICAL ERROR: {e_fnf}\")\n",
    "    if run: run.finish(exit_code=1)\n",
    "    # exit()\n",
    "except ImportError: \n",
    "     print(f\"CRITICAL ERROR loading Excel file: Missing 'openpyxl' library.\")\n",
    "     print(\"Please install 'openpyxl': pip install openpyxl\")\n",
    "     if run: run.finish(exit_code=1)\n",
    "     # exit()\n",
    "except Exception as e_load_data:\n",
    "    print(f\"CRITICAL ERROR occurred while loading the clinical data: {e_load_data}\")\n",
    "    if run: run.finish(exit_code=1)\n",
    "    # exit()\n",
    "\n",
    "# Ensure clinical_df is defined for subsequent cells, even if empty after an error (if not exiting)\n",
    "if clinical_df is None:\n",
    "    clinical_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a687bdf",
   "metadata": {},
   "source": [
    "## 5. Initial Data Inspection: Structure, Statistics, and Missing Values\n",
    "\n",
    "Perform basic checks on the loaded `clinical_df` DataFrame to understand its structure and identify immediate data quality issues. This includes:\n",
    "* Viewing data types, non-null counts, and memory usage using `.info()`.\n",
    "* Calculating descriptive statistics for all columns using `.describe(include='all')`.\n",
    "* Identifying and counting missing values per column using `.isnull().sum()`.\n",
    "\n",
    "Summaries of these inspections are printed and saved locally, and key statistics are logged to W&B.\n",
    "\n",
    "### Missing Value Strategy Note\n",
    "The missing values identified here (especially in columns like MMSE, SES) will be addressed more formally during the preprocessing stage in Notebook 04. Preprocessing, such as imputation, will be performed *after* splitting the data into training, validation, and test sets to prevent data leakage from the validation/test data into the training data's preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e2fc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initial Data Inspection: DataFrame Info and Descriptive Statistics ---\n",
    "if not clinical_df.empty:\n",
    "    print(\"\\n--- Basic Data Information ---\")\n",
    "    print(\"DataFrame Info (clinical_df.info()):\")\n",
    "    clinical_df.info() # Prints to console\n",
    "\n",
    "    print(\"\\nDescriptive Statistics (clinical_df.describe(include='all')):\")\n",
    "    desc_stats = clinical_df.describe(include='all')\n",
    "    display(desc_stats) # For better formatting\n",
    "    #print(desc_stats) # Standard print\n",
    "\n",
    "    # Save descriptive statistics locally to the notebook's output directory\n",
    "    desc_stats_path = output_dir / 'descriptive_stats_raw_data.csv' # Use 'output_dir'\n",
    "    try:\n",
    "        desc_stats.to_csv(desc_stats_path)\n",
    "        print(f\"\\nDescriptive statistics saved locally to: {desc_stats_path}\")\n",
    "    except Exception as e_save_desc:\n",
    "        print(f\"Warning: Could not save descriptive statistics locally. Error: {e_save_desc}\")\n",
    "else:\n",
    "    print(\"\\nSkipping initial data inspection as clinical_df is empty.\")\n",
    "    desc_stats = pd.DataFrame() # Ensure desc_stats is defined for later W&B logging cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254256a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initial Data Inspection: Missing Values ---\n",
    "if not clinical_df.empty:\n",
    "    print(\"\\nMissing Values per Column (showing columns with >0 missing values):\")\n",
    "    missing_values_series = clinical_df.isnull().sum()\n",
    "    missing_values_filtered_df = missing_values_series[missing_values_series > 0].sort_values(ascending=False).reset_index()\n",
    "    missing_values_filtered_df.columns = ['column_name', 'missing_count']\n",
    "    \n",
    "    if not missing_values_filtered_df.empty:\n",
    "        # display(missing_values_filtered_df)\n",
    "        print(missing_values_filtered_df)\n",
    "        # Save missing values summary locally\n",
    "        missing_values_path = output_dir / 'missing_values_summary_raw_data.csv' # Use 'output_dir'\n",
    "        try:\n",
    "            missing_values_filtered_df.to_csv(missing_values_path, index=False)\n",
    "            print(f\"Missing values summary saved locally to: {missing_values_path}\")\n",
    "        except Exception as e_save_missing:\n",
    "            print(f\"Warning: Could not save missing values summary locally. Error: {e_save_missing}\")\n",
    "    else:\n",
    "        print(\"No missing values found in the raw clinical dataset.\")\n",
    "        missing_values_filtered_df = pd.DataFrame(columns=['column_name', 'missing_count']) # Ensure defined for W&B log\n",
    "        missing_values_series = pd.Series(dtype=int) # Ensure defined for W&B log\n",
    "\n",
    "else:\n",
    "    print(\"\\nSkipping missing value analysis as clinical_df is empty.\")\n",
    "    missing_values_filtered_df = pd.DataFrame(columns=['column_name', 'missing_count'])\n",
    "    missing_values_series = pd.Series(dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf71a12",
   "metadata": {},
   "source": [
    "## 6. Log Summary Statistics to Weights & Biases\n",
    "\n",
    "Key summary statistics derived from the initial data inspection are logged to the active W&B run. This provides a quick overview of the dataset characteristics within the W&B interface for this exploration stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acb788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Log Key Dataset Statistics to W&B ---\n",
    "if run and not clinical_df.empty: # Check if W&B run is active and DataFrame is not empty\n",
    "    print(\"\\n--- Logging Summary Dataset Statistics to W&B ---\")\n",
    "    \n",
    "    # Ensure desc_stats, missing_values_series, and missing_values_filtered_df are defined\n",
    "    # (they are initialized to empty DataFrames/Series if clinical_df was empty)\n",
    "    if 'desc_stats' not in locals(): desc_stats = pd.DataFrame()\n",
    "    if 'missing_values_series' not in locals(): missing_values_series = pd.Series(dtype=int)\n",
    "    if 'missing_values_filtered_df' not in locals(): missing_values_filtered_df = pd.DataFrame()\n",
    "\n",
    "    log_summary_dict = {\n",
    "        'dataset/initial_num_rows': clinical_df.shape[0],\n",
    "        'dataset/initial_num_columns': clinical_df.shape[1],\n",
    "        'dataset/total_missing_values': int(missing_values_series.sum()), # Use the series before filtering\n",
    "        'dataset/num_columns_with_missing_values': int(len(missing_values_filtered_df)),\n",
    "        'dataset/memory_usage_mb': float(clinical_df.memory_usage(deep=True).sum() / (1024**2))\n",
    "    }\n",
    "    \n",
    "    # Add descriptive stats for key numerical columns if they exist\n",
    "    # These columns are commonly used in Alzheimer's research.\n",
    "    key_numerical_cols_for_stats = ['Age', 'EDUC', 'SES', 'MMSE', 'CDR', 'eTIV', 'nWBV', 'ASF']\n",
    "    for col_name in key_numerical_cols_for_stats:\n",
    "        if col_name in desc_stats.columns:\n",
    "            # Log common stats like mean, std, min, max if they are numerical\n",
    "            # desc_stats[col_name] might contain non-numeric items like 'top' if include='all'\n",
    "            col_stats = desc_stats[col_name]\n",
    "            if pd.api.types.is_numeric_dtype(col_stats.dtype) or col_stats.name in ['count','mean','std','min','25%','50%','75%','max']: # Check if it contains numeric stats\n",
    "                 for stat_name, stat_val in col_stats.items():\n",
    "                    if pd.api.types.is_number(stat_val) and not pd.isna(stat_val): # Ensure it's a valid number\n",
    "                        log_summary_dict[f'stats_raw/{col_name}_{stat_name.replace(\"%\", \"pct\")}'] = float(stat_val)\n",
    "            elif 'count' in col_stats: # Log at least count for object/categorical\n",
    "                 log_summary_dict[f'stats_raw/{col_name}_count'] = float(col_stats['count'])\n",
    "\n",
    "\n",
    "    try:\n",
    "        run.log(log_summary_dict)\n",
    "        print(\"Summary dataset statistics logged to W&B.\")\n",
    "    except Exception as e_wandb_log_stats:\n",
    "        print(f\"Warning: Could not log summary stats to W&B. Error: {e_wandb_log_stats}\")\n",
    "        \n",
    "elif not clinical_df.empty:\n",
    "    print(\"\\nSkipping W&B logging of summary statistics (W&B run not active).\")\n",
    "else:\n",
    "    print(\"\\nSkipping W&B logging of summary statistics (clinical_df is empty).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eee7913",
   "metadata": {},
   "source": [
    "## 7. Analyze Variable Distributions\n",
    "\n",
    "Visualize the distributions to understand the overall characteristics of the cohort across all recorded visits. This includes:\n",
    "* Histograms for numerical variables (Age, MMSE, nWBV) to observe their spread and central tendency.\n",
    "* Count plots for categorical or discrete variables (Number of Visits per Subject, Clinical Group, Gender) to understand category frequencies.\n",
    "\n",
    "TEach plot is saved locally to this notebook's output directory and logged to the active W&B run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6d0185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Analyze and Visualize Key Variable Distributions ---\n",
    "print(\"\\n--- Analyzing Variable Distributions ---\")\n",
    "\n",
    "if not clinical_df.empty:\n",
    "    # Define a consistent order for 'Group' if it exists, for plotting\n",
    "    group_order_for_plots = None\n",
    "    if 'Group' in clinical_df.columns:\n",
    "        group_order_for_plots = clinical_df['Group'].value_counts().index.tolist()\n",
    "\n",
    "    # Distribution of Age\n",
    "    print(\"Plotting distribution of Age...\")\n",
    "    fig_age_dist, ax_age_dist = plt.subplots(figsize=(10, 5))\n",
    "    sns.histplot(data=clinical_df, x='Age', kde=True, bins=20, ax=ax_age_dist)\n",
    "    ax_age_dist.set_title('Distribution of Age (All Visits)')\n",
    "    ax_age_dist.set_xlabel('Age (Years)')\n",
    "    ax_age_dist.set_ylabel('Frequency')\n",
    "    finalize_plot(fig_age_dist, plt, run, \n",
    "                  f\"charts_eda_{DATASET_IDENTIFIER}/distribution/age\", \n",
    "                  output_dir / '01_age_distribution.png')\n",
    "\n",
    "    # Distribution of MMSE scores (ensure MMSE column exists)\n",
    "    if 'MMSE' in clinical_df.columns:\n",
    "        print(\"Plotting distribution of MMSE Scores...\")\n",
    "        fig_mmse_dist, ax_mmse_dist = plt.subplots(figsize=(10, 5))\n",
    "        sns.histplot(data=clinical_df.dropna(subset=['MMSE']), x='MMSE', kde=True, bins=15, ax=ax_mmse_dist)\n",
    "        ax_mmse_dist.set_title('Distribution of MMSE Scores (All Visits)')\n",
    "        ax_mmse_dist.set_xlabel('MMSE Score')\n",
    "        ax_mmse_dist.set_ylabel('Frequency')\n",
    "        finalize_plot(fig_mmse_dist, plt, run, \n",
    "                      f\"charts_eda_{DATASET_IDENTIFIER}/distribution/mmse\", \n",
    "                      output_dir / '02_mmse_distribution.png')\n",
    "    else:\n",
    "        print(\"MMSE column not found, skipping MMSE distribution plot.\")\n",
    "\n",
    "    # Distribution of nWBV (Normalized Whole Brain Volume)\n",
    "    if 'nWBV' in clinical_df.columns:\n",
    "        print(\"Plotting distribution of nWBV...\")\n",
    "        fig_nwbv_dist, ax_nwbv_dist = plt.subplots(figsize=(10, 5))\n",
    "        sns.histplot(data=clinical_df.dropna(subset=['nWBV']), x='nWBV', kde=True, bins=20, ax=ax_nwbv_dist)\n",
    "        ax_nwbv_dist.set_title('Distribution of Normalized Whole Brain Volume (nWBV - All Visits)')\n",
    "        ax_nwbv_dist.set_xlabel('nWBV')\n",
    "        ax_nwbv_dist.set_ylabel('Frequency')\n",
    "        finalize_plot(fig_nwbv_dist, plt, run, \n",
    "                      f\"charts_eda_{DATASET_IDENTIFIER}/distribution/nwbv\", \n",
    "                      output_dir / '03_nwbv_distribution.png')\n",
    "    else:\n",
    "        print(\"nWBV column not found, skipping nWBV distribution plot.\")\n",
    "\n",
    "    # Count of Visits per Subject\n",
    "    if 'Subject ID' in clinical_df.columns:\n",
    "        print(\"Plotting number of visits per subject...\")\n",
    "        visits_per_subject = clinical_df['Subject ID'].value_counts()\n",
    "        fig_visits_subj, ax_visits_subj = plt.subplots(figsize=(10, 5))\n",
    "        # Plot the counts of these counts for a clearer distribution\n",
    "        sns.countplot(x=visits_per_subject, ax=ax_visits_subj, color='skyblue', stat='count')\n",
    "        ax_visits_subj.set_title('Distribution of Visit Counts per Subject')\n",
    "        ax_visits_subj.set_xlabel('Number of Visits Recorded for a Subject')\n",
    "        ax_visits_subj.set_ylabel('Number of Subjects')\n",
    "        finalize_plot(fig_visits_subj, plt, run, \n",
    "                      f\"charts_eda_{DATASET_IDENTIFIER}/distribution/visits_per_subject\", \n",
    "                      output_dir / '04_visits_per_subject_distribution.png')\n",
    "    else:\n",
    "        print(\"'Subject ID' column not found, skipping visits per subject plot.\")\n",
    "\n",
    "    # Distribution of Clinical Groups (if 'Group' column exists)\n",
    "    if 'Group' in clinical_df.columns:\n",
    "        print(\"Plotting distribution of clinical groups...\")\n",
    "        fig_group_dist, ax_group_dist = plt.subplots(figsize=(8, 5))\n",
    "        sns.countplot(data=clinical_df, x='Group', order=group_order_for_plots, ax=ax_group_dist)\n",
    "        ax_group_dist.set_title('Distribution of Clinical Groups (All Visits)')\n",
    "        ax_group_dist.set_xlabel('Clinical Group')\n",
    "        ax_group_dist.set_ylabel('Number of Visits/Scans')\n",
    "        finalize_plot(fig_group_dist, plt, run, \n",
    "                      f\"charts_eda_{DATASET_IDENTIFIER}/distribution/group\", \n",
    "                      output_dir / '05_clinical_groups_distribution.png')\n",
    "    else:\n",
    "        print(\"'Group' column not found, skipping group distribution plot.\")\n",
    "        \n",
    "    # Distribution of Gender (M/F)\n",
    "    if 'M/F' in clinical_df.columns:\n",
    "        print(\"Plotting distribution of gender...\")\n",
    "        fig_gender_dist, ax_gender_dist = plt.subplots(figsize=(6, 4))\n",
    "        sns.countplot(data=clinical_df, x='M/F', ax=ax_gender_dist)\n",
    "        ax_gender_dist.set_title('Distribution of Gender (All Visits)')\n",
    "        ax_gender_dist.set_xlabel('Gender')\n",
    "        ax_gender_dist.set_ylabel('Number of Visits/Scans')\n",
    "        finalize_plot(fig_gender_dist, plt, run, \n",
    "                      f\"charts_eda_{DATASET_IDENTIFIER}/distribution/gender\", \n",
    "                      output_dir / '06_gender_distribution.png')\n",
    "    else:\n",
    "        print(\"'M/F' column not found, skipping gender distribution plot.\")\n",
    "else:\n",
    "    print(\"Skipping variable distribution analysis as clinical_df is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b59d274",
   "metadata": {},
   "source": [
    "## 8. Analyze Relationships Between Key Variables\n",
    "\n",
    "Explore potential pairwise relationships between important numerical and categorical variables to identify correlations or trends. This includes:\n",
    "* Scatter plots to visualize relationships (e.g., Age vs. MMSE, Age vs. nWBV), often colored by clinical group to reveal group-specific patterns.\n",
    "* A correlation matrix heatmap for key numerical variables to quantify linear associations.\n",
    "\n",
    "These visualizations help in understanding how different factors co-vary within the dataset. Plots are saved locally and logged to W&B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b5e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Analyze and Visualize Relationships Between Key Variables ---\n",
    "print(\"\\n--- Analyzing Relationships Between Variables ---\")\n",
    "\n",
    "if not clinical_df.empty:\n",
    "    # Use group_order_for_plots defined in the previous cell for consistent hue order\n",
    "    current_group_order = None\n",
    "    if 'Group' in clinical_df.columns:\n",
    "        current_group_order = clinical_df['Group'].value_counts().index.tolist() # Ensure it's defined for this cell\n",
    "\n",
    "    # Age vs. MMSE score\n",
    "    if 'Age' in clinical_df.columns and 'MMSE' in clinical_df.columns and 'Group' in clinical_df.columns:\n",
    "        print(\"Plotting Age vs. MMSE Score by Group...\")\n",
    "        fig_age_mmse, ax_age_mmse = plt.subplots(figsize=(10, 6))\n",
    "        sns.scatterplot(data=clinical_df.dropna(subset=['Age', 'MMSE']), \n",
    "                        x='Age', y='MMSE', hue='Group', alpha=0.6, \n",
    "                        ax=ax_age_mmse, hue_order=current_group_order)\n",
    "        ax_age_mmse.set_title('Age vs. MMSE Score by Clinical Group (All Visits)')\n",
    "        ax_age_mmse.set_xlabel('Age (Years)')\n",
    "        ax_age_mmse.set_ylabel('MMSE Score')\n",
    "        finalize_plot(fig_age_mmse, plt, run, \n",
    "                      f\"charts_eda_{DATASET_IDENTIFIER}/relationship/age_vs_mmse\", \n",
    "                      output_dir / '07_age_vs_mmse_by_group.png')\n",
    "    else:\n",
    "        print(\"Skipping Age vs. MMSE plot due to missing columns (Age, MMSE, or Group).\")\n",
    "\n",
    "    # Age vs. nWBV\n",
    "    if 'Age' in clinical_df.columns and 'nWBV' in clinical_df.columns and 'Group' in clinical_df.columns:\n",
    "        print(\"Plotting Age vs. nWBV by Group...\")\n",
    "        fig_age_nwbv, ax_age_nwbv = plt.subplots(figsize=(10, 6))\n",
    "        sns.scatterplot(data=clinical_df.dropna(subset=['Age', 'nWBV']), \n",
    "                        x='Age', y='nWBV', hue='Group', alpha=0.6, \n",
    "                        ax=ax_age_nwbv, hue_order=current_group_order)\n",
    "        ax_age_nwbv.set_title('Age vs. Normalized Whole Brain Volume (nWBV) by Group (All Visits)')\n",
    "        ax_age_nwbv.set_xlabel('Age (Years)')\n",
    "        ax_age_nwbv.set_ylabel('nWBV')\n",
    "        finalize_plot(fig_age_nwbv, plt, run, \n",
    "                      f\"charts_eda_{DATASET_IDENTIFIER}/relationship/age_vs_nwbv\", \n",
    "                      output_dir / '08_age_vs_nwbv_by_group.png')\n",
    "    else:\n",
    "        print(\"Skipping Age vs. nWBV plot due to missing columns (Age, nWBV, or Group).\")\n",
    "\n",
    "    # MMSE vs. nWBV\n",
    "    if 'MMSE' in clinical_df.columns and 'nWBV' in clinical_df.columns and 'Group' in clinical_df.columns:\n",
    "        print(\"Plotting MMSE vs. nWBV by Group...\")\n",
    "        fig_mmse_nwbv, ax_mmse_nwbv = plt.subplots(figsize=(10, 6))\n",
    "        sns.scatterplot(data=clinical_df.dropna(subset=['MMSE', 'nWBV']), \n",
    "                        x='MMSE', y='nWBV', hue='Group', alpha=0.6, \n",
    "                        ax=ax_mmse_nwbv, hue_order=current_group_order)\n",
    "        ax_mmse_nwbv.set_title('MMSE Score vs. nWBV by Group (All Visits)')\n",
    "        ax_mmse_nwbv.set_xlabel('MMSE Score')\n",
    "        ax_mmse_nwbv.set_ylabel('nWBV')\n",
    "        finalize_plot(fig_mmse_nwbv, plt, run, \n",
    "                      f\"charts_eda_{DATASET_IDENTIFIER}/relationship/mmse_vs_nwbv\", \n",
    "                      output_dir / '09_mmse_vs_nwbv_by_group.png')\n",
    "    else:\n",
    "        print(\"Skipping MMSE vs. nWBV plot due to missing columns (MMSE, nWBV, or Group).\")\n",
    "\n",
    "    # Correlation Heatmap for Key Numerical Variables\n",
    "    print(\"Generating Correlation Heatmap...\")\n",
    "    # Define numerical columns intended for correlation analysis\n",
    "    # Ensure these are present in the DataFrame and are indeed numeric\n",
    "    numerical_cols_for_corr = ['Age', 'EDUC', 'SES', 'MMSE', 'CDR', 'Visit', 'eTIV', 'nWBV', 'ASF']\n",
    "    valid_numerical_cols_for_corr = [\n",
    "        col for col in numerical_cols_for_corr \n",
    "        if col in clinical_df.columns and pd.api.types.is_numeric_dtype(clinical_df[col])\n",
    "    ]\n",
    "    \n",
    "    if valid_numerical_cols_for_corr:\n",
    "        correlation_matrix = clinical_df[valid_numerical_cols_for_corr].corr()\n",
    "        fig_corr_matrix, ax_corr_matrix = plt.subplots(figsize=(12, 10)) # Adjusted size\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", \n",
    "                    linewidths=.5, ax=ax_corr_matrix, annot_kws={\"size\": 8})\n",
    "        ax_corr_matrix.set_title('Correlation Matrix of Key Numerical Variables (All Visits)')\n",
    "        plt.xticks(rotation=45, ha='right') # Improve label readability\n",
    "        plt.yticks(rotation=0)\n",
    "        # fig_corr_matrix.tight_layout() # finalize_plot calls this with bbox_inches='tight'\n",
    "        finalize_plot(fig_corr_matrix, plt, run, \n",
    "                      f\"charts_eda_{DATASET_IDENTIFIER}/relationship/correlation_heatmap\", \n",
    "                      output_dir / '10_correlation_matrix.png')\n",
    "    else:\n",
    "        print(\"No valid numerical columns found for correlation heatmap.\")\n",
    "else:\n",
    "    print(\"Skipping variable relationship analysis as clinical_df is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f3c6f9",
   "metadata": {},
   "source": [
    "## 9. Analyze Differences Between Clinical Groups\n",
    "\n",
    "Compare the distributions of key continuous variables (e.g., MMSE, nWBV, Age) across the different clinical groups as defined in the dataset ('Nondemented', 'Converted', 'Demented'). Box plots or violin plots are used to visualize these group differences, providing insights into how these markers vary with cognitive status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb30392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Analyze Differences Between Clinical Groups ---\n",
    "print(\"\\n--- Analyzing Differences Between Clinical Groups ---\")\n",
    "\n",
    "if not clinical_df.empty and 'Group' in clinical_df.columns:\n",
    "    # Define a consistent order for clinical groups for plotting\n",
    "    # This ensures 'Nondemented' typically comes first if present.\n",
    "    # Adjust if your group names or desired order differ.\n",
    "    group_order_for_analysis = ['Nondemented', 'Converted', 'Demented'] \n",
    "    # Filter to include only groups present in the data, maintaining desired order\n",
    "    present_groups_ordered = [g for g in group_order_for_analysis if g in clinical_df['Group'].unique()]\n",
    "    if not present_groups_ordered: # Fallback if predefined order has no matches\n",
    "        present_groups_ordered = clinical_df['Group'].value_counts().index.tolist()\n",
    "\n",
    "\n",
    "    # MMSE scores by group\n",
    "    if 'MMSE' in clinical_df.columns:\n",
    "        print(\"Plotting MMSE Scores by Clinical Group...\")\n",
    "        fig_mmse_group, ax_mmse_group = plt.subplots(figsize=(8, 6))\n",
    "        sns.boxplot(data=clinical_df.dropna(subset=['MMSE']), \n",
    "                    x='Group', y='MMSE', order=present_groups_ordered, ax=ax_mmse_group)\n",
    "        ax_mmse_group.set_title('MMSE Scores by Clinical Group (All Visits)')\n",
    "        ax_mmse_group.set_xlabel('Clinical Group')\n",
    "        ax_mmse_group.set_ylabel('MMSE Score')\n",
    "        finalize_plot(fig_mmse_group, plt, run, \n",
    "                      f\"charts_eda_{DATASET_IDENTIFIER}/group_comparison/mmse_boxplot\", \n",
    "                      output_dir / '11_mmse_by_group_boxplot.png')\n",
    "    else:\n",
    "        print(\"MMSE column not found, skipping MMSE by group plot.\")\n",
    "\n",
    "    # nWBV by group\n",
    "    if 'nWBV' in clinical_df.columns:\n",
    "        print(\"Plotting nWBV by Clinical Group...\")\n",
    "        fig_nwbv_group, ax_nwbv_group = plt.subplots(figsize=(8, 6))\n",
    "        sns.boxplot(data=clinical_df.dropna(subset=['nWBV']), \n",
    "                    x='Group', y='nWBV', order=present_groups_ordered, ax=ax_nwbv_group)\n",
    "        ax_nwbv_group.set_title('nWBV by Clinical Group (All Visits)')\n",
    "        ax_nwbv_group.set_xlabel('Clinical Group')\n",
    "        ax_nwbv_group.set_ylabel('Normalized Whole Brain Volume (nWBV)')\n",
    "        finalize_plot(fig_nwbv_group, plt, run, \n",
    "                      f\"charts_eda_{DATASET_IDENTIFIER}/group_comparison/nwbv_boxplot\", \n",
    "                      output_dir / '12_nwbv_by_group_boxplot.png')\n",
    "    else:\n",
    "        print(\"nWBV column not found, skipping nWBV by group plot.\")\n",
    "\n",
    "    # Age distribution by group\n",
    "    if 'Age' in clinical_df.columns:\n",
    "        print(\"Plotting Age Distribution by Clinical Group...\")\n",
    "        fig_age_group, ax_age_group = plt.subplots(figsize=(8, 6))\n",
    "        sns.violinplot(data=clinical_df.dropna(subset=['Age']), \n",
    "                       x='Group', y='Age', order=present_groups_ordered, ax=ax_age_group)\n",
    "        ax_age_group.set_title('Age Distribution by Clinical Group (All Visits)')\n",
    "        ax_age_group.set_xlabel('Clinical Group')\n",
    "        ax_age_group.set_ylabel('Age (Years)')\n",
    "        finalize_plot(fig_age_group, plt, run, \n",
    "                      f\"charts_eda_{DATASET_IDENTIFIER}/group_comparison/age_violinplot\", \n",
    "                      output_dir / '13_age_by_group_violinplot.png')\n",
    "    else:\n",
    "        print(\"Age column not found, skipping Age by group plot.\")\n",
    "else:\n",
    "    print(\"Skipping group difference analysis as clinical_df is empty or 'Group' column is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87eaba66",
   "metadata": {},
   "source": [
    "## 10. Deeper Longitudinal Analysis\n",
    "\n",
    "To better understand the temporal aspects of the OASIS-2 dataset relevant to cognitive decline, this section explores:\n",
    "1.  **Visit Intervals:** Calculation and distribution of the approximate time elapsed between consecutive visits for each subject. This helps understand the follow-up patterns.\n",
    "2.  **Baseline Characteristics:** Analysis of the subject cohort specifically at their first recorded visit (`Visit == 1`), looking at clinical group distribution, MMSE scores, and age.\n",
    "3.  **Average Longitudinal Trends:** Plotting the average MMSE and nWBV scores across visit numbers, stratified by clinical group, to observe general progression patterns.\n",
    "4.  **Individual Trajectories:** Visualizing MMSE score changes over visits for a few example subjects to highlight inter-subject variability.\n",
    "\n",
    "All generated plots and key statistics are saved locally and logged to W&B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43af97d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Perform Deeper Longitudinal Analysis ---\n",
    "print(\"\\n--- Performing Deeper Longitudinal Analysis ---\")\n",
    "\n",
    "if not clinical_df.empty:\n",
    "    # Ensure data is sorted by Subject ID and Visit for time-based calculations\n",
    "    # Using .copy() to avoid SettingWithCopyWarning on the original clinical_df\n",
    "    df_for_longitudinal = clinical_df.sort_values(by=['Subject ID', 'Visit']).copy()\n",
    "\n",
    "    # --- 1. Calculate Time Between Visits ---\n",
    "    # Prioritize 'MR Delay' (days from a common baseline for the subject) if available and reliable.\n",
    "    # Otherwise, approximate using 'Age'.\n",
    "    print(\"Calculating time intervals between visits...\")\n",
    "    time_feature_source_used = \"Unknown\" # Will be updated based on method used\n",
    "\n",
    "    if 'MR Delay' in df_for_longitudinal.columns and \\\n",
    "       df_for_longitudinal['MR Delay'].isnull().sum() < len(df_for_longitudinal) * 0.5 and \\\n",
    "       pd.api.types.is_numeric_dtype(df_for_longitudinal['MR Delay']):\n",
    "        \n",
    "        print(\"  Using 'MR Delay' (days from study baseline) to calculate time features.\")\n",
    "        # Ensure MR Delay is numeric\n",
    "        df_for_longitudinal['MR Delay_numeric'] = pd.to_numeric(df_for_longitudinal['MR Delay'], errors='coerce')\n",
    "        # Days_from_Baseline for each subject is relative to their *first visit in this dataset*\n",
    "        df_for_longitudinal['BaselineVisitMRDelay'] = df_for_longitudinal.groupby('Subject ID')['MR Delay_numeric'].transform('min')\n",
    "        df_for_longitudinal['Days_from_ThisCohort_Baseline'] = df_for_longitudinal['MR Delay_numeric'] - df_for_longitudinal['BaselineVisitMRDelay']\n",
    "        df_for_longitudinal['Years_Since_Prev_Visit'] = df_for_longitudinal.groupby('Subject ID')['Days_from_ThisCohort_Baseline'].diff() / 365.25\n",
    "        time_feature_source_used = 'MR Delay'\n",
    "    \n",
    "    elif 'Age' in df_for_longitudinal.columns and pd.api.types.is_numeric_dtype(df_for_longitudinal['Age']):\n",
    "        print(\"  Warning: 'MR Delay' not suitable. Using 'Age' to approximate time features.\")\n",
    "        # Days_from_Baseline relative to age at first visit in this cohort\n",
    "        df_for_longitudinal['BaselineAge_ThisCohort'] = df_for_longitudinal.groupby('Subject ID')['Age'].transform('min')\n",
    "        df_for_longitudinal['Days_from_ThisCohort_Baseline'] = (df_for_longitudinal['Age'] - df_for_longitudinal['BaselineAge_ThisCohort']) * 365.25\n",
    "        df_for_longitudinal['Years_Since_Prev_Visit'] = df_for_longitudinal.groupby('Subject ID')['Age'].diff() # Already in years\n",
    "        time_feature_source_used = 'Age_approx'\n",
    "    else:\n",
    "        print(\"  Error: Neither 'MR Delay' nor 'Age' are suitable for calculating time features. Skipping interval analysis.\")\n",
    "        df_for_longitudinal['Years_Since_Prev_Visit'] = np.nan # Ensure column exists if later steps expect it\n",
    "        df_for_longitudinal['Days_from_ThisCohort_Baseline'] = np.nan\n",
    "\n",
    "\n",
    "    # First visit for each subject will have NaN for 'Years_Since_Prev_Visit', fill with 0\n",
    "    df_for_longitudinal['Years_Since_Prev_Visit'] = df_for_longitudinal['Years_Since_Prev_Visit'].fillna(0)\n",
    "\n",
    "    # Analyze distribution of intervals (excluding the first visit's 0)\n",
    "    visit_intervals_years = df_for_longitudinal[df_for_longitudinal['Years_Since_Prev_Visit'] > 0]['Years_Since_Prev_Visit'].dropna()\n",
    "    if not visit_intervals_years.empty:\n",
    "        fig_intervals, ax_intervals = plt.subplots(figsize=(10, 5))\n",
    "        sns.histplot(visit_intervals_years, kde=True, bins=20, ax=ax_intervals)\n",
    "        ax_intervals.set_title(f'Distribution of Approx. Years Between Visits (Source: {time_feature_source_used})')\n",
    "        ax_intervals.set_xlabel('Approx. Years Since Previous Visit')\n",
    "        ax_intervals.set_ylabel('Frequency')\n",
    "        finalize_plot(fig_intervals, plt, run, \n",
    "                      f\"charts_eda_{DATASET_IDENTIFIER}/longitudinal/visit_interval_distribution\", \n",
    "                      output_dir / '14_visit_interval_distribution.png')\n",
    "\n",
    "        interval_stats = visit_intervals_years.describe()\n",
    "        print(\"\\nApproximate Visit Interval Stats (Years, excluding first visits):\")\n",
    "        print(interval_stats)\n",
    "        if run:\n",
    "            run.log({f'stats_longitudinal/visit_interval_{k.replace(\"%\",\"pct\")}': v for k, v in interval_stats.items()})\n",
    "            run.config.update({'eda/time_feature_source_for_intervals': time_feature_source_used}, allow_val_change=True)\n",
    "    else:\n",
    "        print(\"\\nCould not calculate meaningful visit intervals (e.g., only single visits per subject or missing time data).\")\n",
    "\n",
    "    # --- 2. Baseline Characteristics (Visit == 1 in the original Visit numbering) ---\n",
    "    print(\"\\nAnalyzing Baseline Characteristics (Original Visit == 1)...\")\n",
    "    baseline_df = df_for_longitudinal[df_for_longitudinal['Visit'] == 1].copy()\n",
    "\n",
    "    group_order_for_analysis = ['Nondemented', 'Converted', 'Demented'] \n",
    "    present_groups_baseline = [g for g in group_order_for_analysis if g in baseline_df['Group'].unique()] if 'Group' in baseline_df.columns else baseline_df['Group'].value_counts().index.tolist() if 'Group' in baseline_df.columns else []\n",
    "\n",
    "\n",
    "    if not baseline_df.empty:\n",
    "        num_baseline_subjects = baseline_df['Subject ID'].nunique()\n",
    "        print(f\"Number of subjects at baseline (Visit 1): {num_baseline_subjects}\")\n",
    "        if run: run.log({'dataset_baseline/num_subjects': num_baseline_subjects})\n",
    "\n",
    "        if 'Group' in baseline_df.columns:\n",
    "            fig_bl_group, ax_bl_group = plt.subplots(figsize=(8, 5))\n",
    "            sns.countplot(data=baseline_df, x='Group', order=present_groups_baseline, ax=ax_bl_group)\n",
    "            ax_bl_group.set_title('Distribution of Clinical Groups at Baseline (Visit 1)')\n",
    "            finalize_plot(fig_bl_group, plt, run, \n",
    "                          f\"charts_eda_{DATASET_IDENTIFIER}/baseline/group_distribution\", \n",
    "                          output_dir / '15_baseline_group_distribution.png')\n",
    "\n",
    "        if 'MMSE' in baseline_df.columns and 'Group' in baseline_df.columns:\n",
    "            fig_bl_mmse, ax_bl_mmse = plt.subplots(figsize=(8, 6))\n",
    "            sns.boxplot(data=baseline_df.dropna(subset=['MMSE']), x='Group', y='MMSE', order=present_groups_baseline, ax=ax_bl_mmse)\n",
    "            ax_bl_mmse.set_title('MMSE Scores at Baseline (Visit 1) by Group')\n",
    "            finalize_plot(fig_bl_mmse, plt, run, \n",
    "                          f\"charts_eda_{DATASET_IDENTIFIER}/baseline/mmse_boxplot\", \n",
    "                          output_dir / '16_baseline_mmse_boxplot.png')\n",
    "        \n",
    "        if 'Age' in baseline_df.columns and 'Group' in baseline_df.columns:\n",
    "            fig_bl_age, ax_bl_age = plt.subplots(figsize=(8, 6))\n",
    "            sns.violinplot(data=baseline_df.dropna(subset=['Age']), x='Group', y='Age', order=present_groups_baseline, ax=ax_bl_age)\n",
    "            ax_bl_age.set_title('Age Distribution at Baseline (Visit 1) by Group')\n",
    "            finalize_plot(fig_bl_age, plt, run, \n",
    "                          f\"charts_eda_{DATASET_IDENTIFIER}/baseline/age_violinplot\", \n",
    "                          output_dir / '17_baseline_age_violinplot.png')\n",
    "    else:\n",
    "        print(\"No data found for Visit == 1 to analyze baseline characteristics.\")\n",
    "\n",
    "    # --- 3. Average MMSE/nWBV Trends Over Visits ---\n",
    "    print(\"\\nPlotting Average Longitudinal Trends by Group...\")\n",
    "    if 'MMSE' in df_for_longitudinal.columns and 'Visit' in df_for_longitudinal.columns and 'Group' in df_for_longitudinal.columns:\n",
    "        fig_mmse_trend, ax_mmse_trend = plt.subplots(figsize=(10, 6))\n",
    "        sns.lineplot(data=df_for_longitudinal.dropna(subset=['MMSE']), \n",
    "                     x='Visit', y='MMSE', hue='Group', marker='o', \n",
    "                     errorbar='sd', ax=ax_mmse_trend, hue_order=present_groups_baseline)\n",
    "        ax_mmse_trend.set_title('Average MMSE Score Trend over Visits by Group')\n",
    "        ax_mmse_trend.set_xlabel('Visit Number')\n",
    "        ax_mmse_trend.set_ylabel('Average MMSE Score (+/- SD)')\n",
    "        if not df_for_longitudinal['Visit'].empty: ax_mmse_trend.set_xticks(sorted(df_for_longitudinal['Visit'].unique()))\n",
    "        finalize_plot(fig_mmse_trend, plt, run, \n",
    "                      f\"charts_eda_{DATASET_IDENTIFIER}/longitudinal/mmse_trend_by_group\", \n",
    "                      output_dir / '18_mmse_trend_by_group.png')\n",
    "    else:\n",
    "        print(\"Skipping MMSE trend plot due to missing columns (MMSE, Visit, or Group).\")\n",
    "\n",
    "    if 'nWBV' in df_for_longitudinal.columns and 'Visit' in df_for_longitudinal.columns and 'Group' in df_for_longitudinal.columns:\n",
    "        fig_nwbv_trend, ax_nwbv_trend = plt.subplots(figsize=(10, 6))\n",
    "        sns.lineplot(data=df_for_longitudinal.dropna(subset=['nWBV']), \n",
    "                     x='Visit', y='nWBV', hue='Group', marker='o', \n",
    "                     errorbar='sd', ax=ax_nwbv_trend, hue_order=present_groups_baseline)\n",
    "        ax_nwbv_trend.set_title('Average nWBV Trend over Visits by Group')\n",
    "        ax_nwbv_trend.set_xlabel('Visit Number')\n",
    "        ax_nwbv_trend.set_ylabel('Average nWBV (+/- SD)')\n",
    "        if not df_for_longitudinal['Visit'].empty: ax_nwbv_trend.set_xticks(sorted(df_for_longitudinal['Visit'].unique()))\n",
    "        finalize_plot(fig_nwbv_trend, plt, run, \n",
    "                      f\"charts_eda_{DATASET_IDENTIFIER}/longitudinal/nwbv_trend_by_group\", \n",
    "                      output_dir / '19_nwbv_trend_by_group.png')\n",
    "    else:\n",
    "        print(\"Skipping nWBV trend plot due to missing columns (nWBV, Visit, or Group).\")\n",
    "\n",
    "    # --- 4. Individual MMSE Trajectories (Spaghetti Plot) ---\n",
    "    print(\"\\nPlotting Example Individual MMSE Trajectories...\")\n",
    "    if 'Subject ID' in df_for_longitudinal.columns and 'MMSE' in df_for_longitudinal.columns and 'Visit' in df_for_longitudinal.columns:\n",
    "        # Select a few subjects, trying to get representation from different groups if possible\n",
    "        example_subject_ids = []\n",
    "        if 'Group' in df_for_longitudinal.columns:\n",
    "            for grp_val in present_groups_baseline if present_groups_baseline else df_for_longitudinal['Group'].unique():\n",
    "                subjects_in_grp = df_for_longitudinal[df_for_longitudinal['Group'] == grp_val]['Subject ID'].unique()\n",
    "                if len(subjects_in_grp) > 0:\n",
    "                    example_subject_ids.extend(np.random.choice(subjects_in_grp, size=min(2, len(subjects_in_grp)), replace=False))\n",
    "        else: # If no group, just take some random subjects\n",
    "            all_subjects = df_for_longitudinal['Subject ID'].unique()\n",
    "            if len(all_subjects) > 0:\n",
    "                example_subject_ids.extend(np.random.choice(all_subjects, size=min(5, len(all_subjects)), replace=False))\n",
    "        \n",
    "        example_subject_ids = list(set(example_subject_ids)) # Unique subjects\n",
    "\n",
    "        if example_subject_ids:\n",
    "            example_trajectories_df = df_for_longitudinal[df_for_longitudinal['Subject ID'].isin(example_subject_ids)].copy()\n",
    "            \n",
    "            fig_ind_traj, ax_ind_traj = plt.subplots(figsize=(12, 7))\n",
    "            sns.lineplot(data=example_trajectories_df.dropna(subset=['MMSE']),\n",
    "                         x='Visit', y='MMSE', hue='Subject ID', \n",
    "                         style='Group' if 'Group' in example_trajectories_df.columns else None, \n",
    "                         marker='o', ax=ax_ind_traj, legend=\"brief\") # 'full' legend can be too large\n",
    "            ax_ind_traj.set_title('Individual MMSE Score Trends for Example Subjects')\n",
    "            ax_ind_traj.set_xlabel('Visit Number')\n",
    "            ax_ind_traj.set_ylabel('MMSE Score')\n",
    "            if not example_trajectories_df['Visit'].empty: ax_ind_traj.set_xticks(sorted(example_trajectories_df['Visit'].unique()))\n",
    "            \n",
    "            # Improve legend placement if many subjects\n",
    "            if len(example_subject_ids) > 5 :\n",
    "                ax_ind_traj.legend(title=\"Subject (Style=Group)\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "                fig_ind_traj.tight_layout(rect=[0, 0, 0.85, 1]) # Adjust layout for external legend\n",
    "            else:\n",
    "                ax_ind_traj.legend(title=\"Subject (Style=Group)\")\n",
    "                fig_ind_traj.tight_layout()\n",
    "\n",
    "            finalize_plot(fig_ind_traj, plt, run, \n",
    "                          f\"charts_eda_{DATASET_IDENTIFIER}/longitudinal/mmse_individual_examples\", \n",
    "                          output_dir / '20_mmse_individual_examples.png')\n",
    "        else:\n",
    "            print(\"Could not select example subjects for individual trajectory plot.\")\n",
    "    else:\n",
    "        print(\"Skipping individual MMSE trajectories plot due to missing columns.\")\n",
    "else:\n",
    "    print(\"Skipping deeper longitudinal analysis as clinical_df is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c453332a",
   "metadata": {},
   "source": [
    "## 11. Verify MRI Scan File Availability\n",
    "\n",
    "This section verifies that the raw MRI scan files, corresponding to the `MRI ID` and `Subject ID` in the clinical dataset, exist in the local file system. This step:\n",
    "* Iterates through each visit record in the loaded `clinical_df`.\n",
    "* For each record, constructs the expected file path for the raw T1w MPRAGE scan data (looking for `.nifti.img` and `.nifti.hdr` pairs within a `RAW` subfolder, across the base MRI data paths defined in `config.json`).\n",
    "* Checks for the existence of the scan folder and the required image file pairs.\n",
    "* Records detailed verification status for each scan session.\n",
    "\n",
    "*Note on OASIS-2 MPRAGE Scans:* The OASIS dataset typically includes 3-4 individual T1w MPRAGE acquisitions per imaging session. This verification checks for these and notes if at least three are found, as this often indicates a complete acquisition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf0b5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Verify Local Availability of Raw MRI Scan Files ---\n",
    "print(f\"\\n--- Verifying Local MPRAGE Files (.img + .hdr pairs) ---\")\n",
    "print(f\"Using MRI Base Paths: {[str(p) for p in MRI_BASE_PATHS_ABSOLUTE]}\") # From Cell 3\n",
    "print(f\"Using Pattern: {MPR_IMG_PATTERN_CONFIG.pattern}\") # From Cell 3\n",
    "print(f\"Expecting structure like: <mri_base_path>/<MRI ID>/RAW/mpr-<#>.nifti.{{img,hdr}}\")\n",
    "\n",
    "verification_log_entries = [] # To store detailed log dictionaries for each scan\n",
    "\n",
    "if not clinical_df.empty and MRI_BASE_PATHS_ABSOLUTE:\n",
    "    # Check if *at least one* base path actually exists (as a directory)\n",
    "    any_base_path_is_valid = any(p.is_dir() for p in MRI_BASE_PATHS_ABSOLUTE)\n",
    "    if not any_base_path_is_valid:\n",
    "        print(f\"CRITICAL ERROR: None of the configured base MRI paths exist or are directories.\")\n",
    "        print(f\"  Checked paths: {[str(p) for p in MRI_BASE_PATHS_ABSOLUTE]}\")\n",
    "        print(\"Skipping image file verification. Subsequent preprocessing will likely fail.\")\n",
    "        if run:\n",
    "            run.log({'verification/error_any_mri_base_path_invalid': True})\n",
    "            # run.finish(exit_code=1) # Consider exiting if this is critical\n",
    "        # To allow notebook to complete if this is an error, we create an empty verification_df\n",
    "        verification_df = pd.DataFrame(columns=['mri_id', 'subject_id', 'visit', 'group', \n",
    "                                                'mri_base_path_used', 'mri_folder_path_checked', \n",
    "                                                'mri_folder_exists', 'mprs_found_count', \n",
    "                                                'mpr_labels_found', 'found_three_or_more_mprs', \n",
    "                                                'error_listing_dir'])\n",
    "    else:\n",
    "        if run: run.log({'verification/info_mri_base_paths_valid': True})\n",
    "\n",
    "        print(\"\\nStarting scan file verification process...\")\n",
    "        verification_start_time = time.time()\n",
    "\n",
    "        # Iterate through each row (visit) in the clinical dataframe\n",
    "        for index, row in tqdm(clinical_df.iterrows(), total=len(clinical_df), desc=\"Verifying Scan Files\"):\n",
    "            log_entry = verify_scan_files(row, MRI_BASE_PATHS_ABSOLUTE, MPR_IMG_PATTERN_CONFIG)\n",
    "            verification_log_entries.append(log_entry)\n",
    "            \n",
    "            # Optional: Print immediate feedback for missing folders if verbose\n",
    "            # if not log_entry['mri_folder_exists']:\n",
    "            #     print(f\"  [Missing Folder] MRI ID {log_entry['mri_id']} ({log_entry['subject_id']}): \"\n",
    "            #           f\"Checked {log_entry['mri_folder_path_checked']}\")\n",
    "        \n",
    "        verification_df = pd.DataFrame(verification_log_entries) # Create DataFrame from all log entries\n",
    "        verification_duration = time.time() - verification_start_time\n",
    "        print(f\"\\nFinished scan verification in {verification_duration:.2f} seconds.\")\n",
    "        if run: run.log({'verification/duration_seconds': verification_duration})\n",
    "else:\n",
    "    print(\"Skipping MRI scan file verification: clinical_df is empty or MRI_BASE_PATHS not defined.\")\n",
    "    # Ensure verification_df exists and is empty for downstream cells\n",
    "    verification_df = pd.DataFrame(columns=['mri_id', 'subject_id', 'visit', 'group', \n",
    "                                            'mri_base_path_used', 'mri_folder_path_checked',\n",
    "                                            'mri_folder_exists', 'mprs_found_count', \n",
    "                                            'mpr_labels_found', 'found_three_or_more_mprs',\n",
    "                                            'error_listing_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9380171",
   "metadata": {},
   "source": [
    "## 12. Final MRI Verification Summary, Logging, and Output Saving\n",
    "\n",
    "This section summarizes the results of the MRI file verification process:\n",
    "* Total MRI IDs processed from the clinical data.\n",
    "* Number of expected scan folders found versus missing.\n",
    "* Total count of valid MPRAGE scan pairs (`.img` + `.hdr`) located.\n",
    "* Number of unique subjects for whom at least one scan pair was found.\n",
    "* Number of unique subjects who have at least one scan session with three or more MPRAGE pairs (indicative of a complete OASIS-2 acquisition).\n",
    "\n",
    "These summary statistics are printed and logged to W&B. The detailed, per-scan verification results are saved locally to `verification_details.csv` (in this notebook's output directory) and also logged as a `wandb.Table` for detailed inspection in the W&B interface. A list of MRI IDs for which scan folders were not found is also saved locally and logged as a W&B artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23141487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Process and Summarize MRI Verification Results ---\n",
    "print(\"\\n--- Processing and Summarizing MRI Verification Results ---\")\n",
    "\n",
    "if not verification_df.empty:\n",
    "    # Calculate summary statistics from the verification_df\n",
    "    num_mri_ids_in_clinical_df = verification_df['mri_id'].nunique() # Unique MRI IDs checked\n",
    "    num_folders_found = verification_df['mri_folder_exists'].sum()\n",
    "    num_folders_missing = num_mri_ids_in_clinical_df - num_folders_found # More accurate if some MRI IDs were duplicated in clinical_df but unique in verification_df\n",
    "    \n",
    "    total_mpr_pairs_located = verification_df['mprs_found_count'].sum()\n",
    "    \n",
    "    # Subjects for whom at least one scan file (any mpr pair) was found\n",
    "    subjects_with_any_verified_mprs = verification_df[verification_df['mprs_found_count'] > 0]['subject_id'].nunique()\n",
    "    # Subjects who have at least one scan session where 3+ mpr pairs were found\n",
    "    subjects_with_at_least_one_complete_scan_session = verification_df[verification_df['found_three_or_more_mprs'] == True]['subject_id'].nunique()\n",
    "\n",
    "    print(\"\\n--- Final MRI Scan File Verification Summary ---\")\n",
    "    print(f\"Total unique MRI IDs from clinical data processed: {num_mri_ids_in_clinical_df}\")\n",
    "    print(f\"  Corresponding scan folders found: {num_folders_found}\")\n",
    "    print(f\"  Corresponding scan folders missing: {num_folders_missing}\")\n",
    "    print(f\"Total complete MPRAGE pairs (.img + .hdr) located across all found folders: {total_mpr_pairs_located}\")\n",
    "    print(f\"Unique subjects with at least one MPRAGE pair found: {subjects_with_any_verified_mprs}\")\n",
    "    print(f\"Unique subjects with at least one scan session having >= 3 MPRAGE pairs: {subjects_with_at_least_one_complete_scan_session}\")\n",
    "\n",
    "    # Save detailed verification results DataFrame locally\n",
    "    verification_output_filename = f\"verification_details_{DATASET_IDENTIFIER}.csv\"\n",
    "    verification_output_path = output_dir / verification_output_filename\n",
    "    try:\n",
    "        verification_df.to_csv(verification_output_path, index=False)\n",
    "        print(f\"\\nDetailed verification results saved locally to: {verification_output_path}\")\n",
    "    except Exception as e_save_verif:\n",
    "        print(f\"Warning: Could not save detailed verification results locally. Error: {e_save_verif}\")\n",
    "    \n",
    "    # Save list of missing folders locally\n",
    "    missing_folders_df = verification_df[verification_df['mri_folder_exists'] == False][['mri_id', 'subject_id', 'visit', 'group', 'mri_folder_path_checked']]\n",
    "    if not missing_folders_df.empty:\n",
    "        missing_folders_filename = f\"missing_mri_folders_{DATASET_IDENTIFIER}.csv\"\n",
    "        missing_folders_path = output_dir / missing_folders_filename\n",
    "        try:\n",
    "            missing_folders_df.to_csv(missing_folders_path, index=False)\n",
    "            print(f\"List of {len(missing_folders_df)} missing MRI folders saved locally to: {missing_folders_path}\")\n",
    "        except Exception as e_save_missing_folders:\n",
    "            print(f\"Warning: Could not save missing MRI folders list locally. Error: {e_save_missing_folders}\")\n",
    "\n",
    "    # Log to W&B\n",
    "    if run:\n",
    "        print(\"\\nLogging verification summary and details to W&B...\")\n",
    "        run.log({\n",
    "            'verification/total_mri_ids_checked': num_mri_ids_in_clinical_df,\n",
    "            'verification/scan_folders_found': num_folders_found,\n",
    "            'verification/scan_folders_missing': num_folders_missing,\n",
    "            'verification/total_mpr_pairs_located': total_mpr_pairs_located,\n",
    "            'verification/subjects_with_any_mprs': subjects_with_any_verified_mprs,\n",
    "            'verification/subjects_with_min_3_mprs_in_a_scan': subjects_with_at_least_one_complete_scan_session\n",
    "        })\n",
    "        \n",
    "        # Log the detailed verification DataFrame as a W&B Table\n",
    "        try:\n",
    "            verification_wandb_table = wandb.Table(dataframe=verification_df)\n",
    "            run.log({\"verification/scan_verification_details_table\": verification_wandb_table})\n",
    "            print(\"Detailed verification results logged as W&B Table.\")\n",
    "        except Exception as e_wandb_table:\n",
    "            print(f\"Warning: Could not log verification details table to W&B. Error: {e_wandb_table}\")\n",
    "\n",
    "        # Log the verification_details.csv itself as an artifact for direct download\n",
    "        try:\n",
    "            verif_details_artifact_name = f\"verification_details_{DATASET_IDENTIFIER}\"\n",
    "            verif_details_artifact = wandb.Artifact(\n",
    "                verif_details_artifact_name, \n",
    "                type=\"dataset_verification_report\",\n",
    "                description=f\"Detailed MRI scan file verification status for {DATASET_IDENTIFIER}.\"\n",
    "            )\n",
    "            verif_details_artifact.add_file(str(verification_output_path))\n",
    "            run.log_artifact(verif_details_artifact, aliases=[\"latest\"])\n",
    "            print(f\"'{verification_output_filename}' logged as W&B Artifact.\")\n",
    "        except Exception as e_wandb_art_verif:\n",
    "            print(f\"Warning: Could not log verification_details.csv as W&B artifact. Error: {e_wandb_art_verif}\")\n",
    "\n",
    "        # Log missing folders list as a W&B artifact if it exists and was saved\n",
    "        if not missing_folders_df.empty and missing_folders_path.exists():\n",
    "            try:\n",
    "                missing_folders_artifact_name = f\"missing_mri_folders_report_{DATASET_IDENTIFIER}\"\n",
    "                missing_folders_artifact = wandb.Artifact(\n",
    "                    missing_folders_artifact_name, \n",
    "                    type=\"analysis_output\",\n",
    "                    description=f\"List of MRI IDs for {DATASET_IDENTIFIER} whose scan folders were not found.\"\n",
    "                )\n",
    "                missing_folders_artifact.add_file(str(missing_folders_path))\n",
    "                run.log_artifact(missing_folders_artifact)\n",
    "                print(f\"List of {len(missing_folders_df)} missing folders logged as W&B Artifact.\")\n",
    "            except Exception as e_wandb_art_missing:\n",
    "                print(f\"Warning: Could not log missing_folders.csv as W&B artifact. Error: {e_wandb_art_missing}\")\n",
    "        elif missing_folders_df.empty:\n",
    "            print(\"No missing MRI folders found to log as artifact.\")\n",
    "else:\n",
    "    print(\"Verification DataFrame is empty. Skipping summary, saving, and W&B logging of verification results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7c717b",
   "metadata": {},
   "source": [
    "## Finalize Run\n",
    "\n",
    "Complete the execution for this notebook and finish the associated Weights & Biases run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750c8968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Finish W&B Run ---\n",
    "print(\"\\n--- Exploration and Verification complete. Finishing W&B run. ---\")\n",
    "if run:\n",
    "    run.finish()\n",
    "    print(\"W&B run finished.\")\n",
    "else:\n",
    "    print(\"No active W&B run to finish.\")\n",
    "\n",
    "print(\"\\nScript execution finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro_predcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
