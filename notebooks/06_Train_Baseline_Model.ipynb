{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In: notebooks/06_Train_Baseline_Model.ipynb\n",
    "# Purpose: Train the baseline LSTM regression model to predict next CDR score\n",
    "#          using pre-computed features and the prepared data splits.\n",
    "#          Loads configuration (feature lists, etc.) from the relevant NB04 W&B run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Notebook 06: Train Baseline LSTM Model\n",
    "\n",
    "**Purpose:** Train the baseline LSTM regression model, defined in `src/models.py`, to predict the next CDR score based on longitudinal clinical/demographic features.\n",
    "\n",
    "**Workflow:**\n",
    "1.  **Setup:** Load base configuration (`config.json`), define training hyperparameters (`HP`), define paths to data splits and preprocessors.\n",
    "2.  **Fetch Prior Config:** Use the W&B API to load the definitive configuration (feature lists, preprocessing column lists) logged by the successful run of Notebook 04 (`04_Fit_Preprocessors.ipynb`). This ensures consistency.\n",
    "3.  **Initialize W&B Run:** Start a *new* W&B run specifically for this training job, logging all hyperparameters (`HP`) including the fetched configuration details.\n",
    "4.  **Setup Device:** Detect and set the appropriate device (GPU or CPU) for PyTorch.\n",
    "5.  **Load Data:** Instantiate `OASISDataset` (using the fetched config) for train and validation splits and create PyTorch `DataLoader`s using the custom `pad_collate_fn`.\n",
    "6.  **Define Model:** Instantiate the `BaselineLSTMRegressor` model, loss function (`MSELoss`), and optimizer (`Adam`).\n",
    "7.  **Train & Validate:** Run the main training loop:\n",
    "     * Iterate through epochs.\n",
    "     * Perform training step (forward pass, loss calculation, backward pass, optimizer step).\n",
    "     * Perform validation step (forward pass, loss calculation, no gradients).\n",
    "     * Calculate metrics (MSE, MAE, R2) for train and validation sets.\n",
    "     * Log metrics to W&B.\n",
    "     * Implement model checkpointing (save best model based on validation loss) locally and as a W&B artifact.\n",
    "     * Implement early stopping based on validation loss patience.\n",
    " 8.  **Finalize:** Finish the W&B run, logging summary metrics.\n",
    "\n",
    " **Input:**\n",
    " * `cohort_{train|validation}.parquet` (From NB 03)\n",
    " * `standard_scaler.joblib`, `simple_imputer_median.joblib` (From NB 04)\n",
    " * Configuration logged by NB 04 run (fetched via W&B API)\n",
    " * `src/datasets.py`, `src/models.py`\n",
    "\n",
    " **Output:**\n",
    " * Trained model checkpoints (`.pth` files saved locally in `notebooks/outputs/06_.../` under a run-specific folder).\n",
    " * W&B Run: Logs hyperparameters, metrics (loss, MAE, R2), best model checkpoint artifact.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Setup: Imports, Paths, Config, Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Standard Libraries & Imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "import json\n",
    "from pathlib import Path\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Add src directory to Python path ---\n",
    "try:\n",
    "    module_path = os.path.abspath(os.path.join('..'))\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "    print(f\"Added {module_path} to sys.path\")\n",
    "    # --- Import custom classes/functions ---\n",
    "    from src.datasets import OASISDataset, pad_collate_fn\n",
    "    from src.models import BaselineLSTMRegressor # Import the model definition\n",
    "    print(\"Successfully imported custom Dataset and Model.\")\n",
    "except ModuleNotFoundError:\n",
    "     print(\"Error: Could not import from src directory.\")\n",
    "     print(\"Ensure src/datasets.py and src/models.py exist.\")\n",
    "     exit()\n",
    "except Exception as e:\n",
    "     print(f\"An unexpected error occurred during import: {e}\")\n",
    "     exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Config Loading, Hyperparameters & Fetching Prior Config ---\n",
    "print(\"\\n--- Loading Configuration, Setting Hyperparameters, Fetching Prior Config ---\")\n",
    "CONFIG_PATH = Path('../config.json')\n",
    "nb04_config = {} # To store config fetched from NB04 run\n",
    "\n",
    "try:\n",
    "    # Load base config (paths, W&B project/entity)\n",
    "    PROJECT_ROOT = CONFIG_PATH.parent.resolve()\n",
    "    with open(CONFIG_PATH, 'r', encoding='utf-8') as f:\n",
    "        base_config = json.load(f)\n",
    "        WANDB_PROJECT = base_config['wandb']['project_name']\n",
    "        WANDB_ENTITY = base_config['wandb'].get('entity', None)\n",
    "    print(\"Base configuration loaded successfully.\")\n",
    "\n",
    "    # --- Define Training Hyperparameters ---\n",
    "    HP = {\n",
    "        'batch_size': 32,\n",
    "        'learning_rate': 1e-4,\n",
    "        'epochs': 50,\n",
    "        'lstm_hidden_size': 128,\n",
    "        'lstm_num_layers': 2,\n",
    "        'lstm_dropout_prob': 0.3,\n",
    "        'num_workers': 0,\n",
    "        'random_seed': 42,\n",
    "        # Preprocessing strategies below should ideally match NB04 config, used for path finding primarily\n",
    "        'imputation_strategy': 'median',\n",
    "        'scaling_strategy': 'StandardScaler',\n",
    "    }\n",
    "    print(\"Training hyperparameters set.\")\n",
    "\n",
    "    # --- Define Paths ---\n",
    "    OUTPUT_DIR_BASE = PROJECT_ROOT / base_config['data']['output_dir_base']\n",
    "    NB03_OUTPUT_DIR = OUTPUT_DIR_BASE / \"03_Feature_Engineering_Splitting\"\n",
    "    NB04_OUTPUT_DIR = OUTPUT_DIR_BASE / \"04_Fit_Preprocessors\"\n",
    "    NB06_OUTPUT_DIR = OUTPUT_DIR_BASE / \"06_Train_Baseline_Model\"\n",
    "    NB06_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    TRAIN_DATA_PATH = NB03_OUTPUT_DIR / \"cohort_train.parquet\"\n",
    "    VAL_DATA_PATH = NB03_OUTPUT_DIR / \"cohort_validation.parquet\"\n",
    "    TEST_DATA_PATH = NB03_OUTPUT_DIR / \"cohort_test.parquet\" # Define but likely use in NB07\n",
    "    SCALER_PATH = NB04_OUTPUT_DIR / f\"{HP['scaling_strategy'].lower()}.joblib\" # Construct path dynamically\n",
    "    IMPUTER_PATH = NB04_OUTPUT_DIR / f\"simple_imputer_{HP['imputation_strategy']}.joblib\"\n",
    "\n",
    "    # --- Fetch Configuration from NB04 W&B Run ---\n",
    "    print(\"\\nFetching configuration from NB04 W&B Run...\")\n",
    "    # *** IMPORTANT: Replace with actual Run Path \"entity/project/run_id\" from NB04 ***\n",
    "    nb04_run_id = \"RUN_PATH_FROM_NB04\"\n",
    "    # Ensure WANDB_ENTITY and WANDB_PROJECT were loaded correctly from config.json\n",
    "    if not WANDB_PROJECT or not WANDB_ENTITY:\n",
    "        raise ValueError(\"WANDB_PROJECT or WANDB_ENTITY not defined. Check config loading.\")\n",
    "    nb04_run_path = f\"{WANDB_ENTITY}/{WANDB_PROJECT}/{nb04_run_id}\"\n",
    "\n",
    "    try:\n",
    "        # Ensure wandb is logged in if needed (wandb login)\n",
    "        api = wandb.Api(timeout=19) # Increase timeout if needed\n",
    "        nb04_run = api.run(nb04_run_path)\n",
    "        nb04_config = nb04_run.config # Fetch the entire config dict logged by NB04\n",
    "        print(f\"Successfully fetched config from NB04 run: {nb04_run_path}\")\n",
    "\n",
    "        # Extract feature/preprocess lists and add them to HP for logging with this run\n",
    "        # Use .get() for safety in case keys slightly differ\n",
    "        features_dict = nb04_config.get('features', {})\n",
    "        preprocess_dict = nb04_config.get('preprocess', {})\n",
    "\n",
    "        HP['features_time_varying'] = features_dict.get('time_varying', [])\n",
    "        HP['features_static'] = features_dict.get('static', [])\n",
    "        HP['input_size'] = len(HP['features_time_varying']) + len(HP['features_static'])\n",
    "        HP['preprocess_scaling_cols'] = preprocess_dict.get('scaling_cols', [])\n",
    "        HP['preprocess_imputation_cols'] = preprocess_dict.get('imputation_cols', [])\n",
    "        HP['source_config_run_id'] = nb04_run_path # Track provenance\n",
    "\n",
    "        print(\"-\" * 20)\n",
    "        print(\"DEBUG NB06: Config Fetched from W&B (NB04 Run)\")\n",
    "        print(f\"  Time Varying ({len(HP['features_time_varying'])}): {HP['features_time_varying']}\")\n",
    "        print(f\"  Static ({len(HP['features_static'])}): {HP['features_static']}\")\n",
    "        print(f\"  Calculated HP['input_size']: {HP['input_size']}\") # Should be 12\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "        # Validate loaded config\n",
    "        if not HP['features_time_varying'] or not HP['features_static'] or HP['input_size'] == 0:\n",
    "             raise ValueError(\"Loaded feature lists from NB04 config are empty or invalid.\")\n",
    "        print(f\"Input size calculated from fetched features: {HP['input_size']}\")\n",
    "        print(f\"  Fetched Time Varying: {HP['features_time_varying']}\")\n",
    "        print(f\"  Fetched Static: {HP['features_static']}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching config from W&B run '{nb04_run_path}': {e}\")\n",
    "        print(\"This notebook requires the configuration (esp. feature lists) logged by NB04.\")\n",
    "        print(\"Please ensure NB04 ran successfully, logged the config correctly, and update 'nb04_run_path'.\")\n",
    "        exit()\n",
    "\n",
    "    # --- Seed for reproducibility ---\n",
    "    np.random.seed(HP['random_seed'])\n",
    "    torch.manual_seed(HP['random_seed'])\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(HP['random_seed'])\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during configuration setup: {e}\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Initialize W&B Training Run\n",
    "\n",
    "Start a new Weights & Biases run specifically for this training experiment. We log all hyperparameters defined in the `HP` dictionary, which now includes the feature lists and preprocessing details fetched from the NB04 run, ensuring full traceability. A unique directory is created for saving model checkpoints locally for this run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initialize W&B Run for THIS Training Job ---\n",
    "print(\"\\n--- Initializing Weights & Biases Run for Training ---\")\n",
    "run = None\n",
    "try:\n",
    "    run = wandb.init(\n",
    "        project=WANDB_PROJECT,\n",
    "        entity=WANDB_ENTITY,\n",
    "        job_type=\"train-baseline-lstm\",\n",
    "        name=f\"train-lstm-hs{HP['lstm_hidden_size']}-nl{HP['lstm_num_layers']}-dp{HP['lstm_dropout_prob']}-{time.strftime('%Y%m%d-%H%M')}\",\n",
    "        config=HP # Log all hyperparameters, including fetched feature lists and source run ID\n",
    "    )\n",
    "    print(f\"W&B run '{run.name}' initialized successfully. View at: {run.url}\")\n",
    "    # Define output directory for this specific run's checkpoints\n",
    "    run_output_dir = NB06_OUTPUT_DIR / run.name\n",
    "    run_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Checkpoints for this run will be saved to: {run_output_dir}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing W&B: {e}\")\n",
    "    print(\"Proceeding without W&B logging.\")\n",
    "    run_output_dir = NB06_OUTPUT_DIR / f\"local_run_{time.strftime('%Y%m%d-%H%M%S')}\"\n",
    "    run_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Proceeding locally. Checkpoints will be saved to: {run_output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Setup Device\n",
    "\n",
    "Check for CUDA availability and set the PyTorch device accordingly (GPU or CPU).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Setup Device (GPU/CPU) ---\n",
    "# (Keep this cell as it was - looks correct)\n",
    "print(\"\\n--- Setting up Device ---\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"CUDA is available. Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA not available. Using CPU.\")\n",
    "if run: run.config.update({'device': str(device)}, allow_val_change=True) # Log device used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Load Data & Create DataLoaders\n",
    "\n",
    "Instantiate the custom `OASISDataset` for the training and validation data splits. Crucially, pass the configuration dictionary (`nb04_config`) fetched from the NB04 W&B run to ensure the Dataset uses the correct feature lists and applies the corresponding preprocessors internally. Then, wrap these datasets in PyTorch `DataLoader`s, specifying batch size and using the `pad_collate_fn` to handle variable sequence lengths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Instantiate Datasets and DataLoaders ---\n",
    "print(\"\\n--- Loading Data and Creating DataLoaders ---\")\n",
    "try:\n",
    "    print(\"Instantiating training dataset...\")\n",
    "    # --- Pass the NB04 Config ---\n",
    "    train_dataset = OASISDataset(TRAIN_DATA_PATH, SCALER_PATH, IMPUTER_PATH, config=nb04_config)\n",
    "\n",
    "    print(\"Instantiating validation dataset...\")\n",
    "    # --- Pass the NB04 Config ---\n",
    "    val_dataset = OASISDataset(VAL_DATA_PATH, SCALER_PATH, IMPUTER_PATH, config=nb04_config)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=HP['batch_size'], shuffle=True,\n",
    "        collate_fn=pad_collate_fn, num_workers=HP['num_workers'], persistent_workers=(HP['num_workers']>0)\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=HP['batch_size'], shuffle=False,\n",
    "        collate_fn=pad_collate_fn, num_workers=HP['num_workers'], persistent_workers=(HP['num_workers']>0)\n",
    "    )\n",
    "    print(\"Train and Validation DataLoaders created.\")\n",
    "    # Use the input_size calculated from fetched config and stored in HP\n",
    "    print(f\"Input size (num features) for model: {HP['input_size']}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "     print(f\"Error: Data file or preprocessor file not found: {e}\")\n",
    "     print(\"Ensure notebooks 01-04 ran successfully and paths in config are correct.\")\n",
    "     if run: run.finish()\n",
    "     exit()\n",
    "except Exception as e:\n",
    "     print(f\"Error creating Datasets/DataLoaders: {e}\")\n",
    "     if run: run.finish()\n",
    "     exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Define Model, Loss, Optimizer\n",
    "\n",
    "Instantiate the `BaselineLSTMRegressor` model using the input size determined from the fetched configuration. Define the Mean Squared Error loss function (suitable for regression) and the Adam optimizer. Optionally, use `wandb.watch` to monitor model gradients and parameters during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# --- Instantiate Model, Loss, Optimizer ---\n",
    "print(\"\\n--- Initializing Model, Loss Function, and Optimizer ---\")\n",
    "try:\n",
    "    # Instantiate the model\n",
    "    model = BaselineLSTMRegressor(\n",
    "        input_size=HP['input_size'],\n",
    "        hidden_size=HP['lstm_hidden_size'],\n",
    "        num_layers=HP['lstm_num_layers'],\n",
    "        dropout_prob=HP['lstm_dropout_prob']\n",
    "    )\n",
    "    model.to(device) # Move model to GPU if available\n",
    "    print(\"Model instantiated:\")\n",
    "    print(model)\n",
    "\n",
    "    # Define the Loss Function (Criterion)\n",
    "    # Mean Squared Error is common for regression tasks like predicting CDR score\n",
    "    criterion = nn.MSELoss()\n",
    "    print(f\"Loss function: {type(criterion).__name__}\")\n",
    "\n",
    "    # Define the Optimizer\n",
    "    # Adam is a popular choice\n",
    "    optimizer = optim.Adam(model.parameters(), lr=HP['learning_rate'])\n",
    "    print(f\"Optimizer: {type(optimizer).__name__} with LR={HP['learning_rate']}\")\n",
    "\n",
    "    # Watch model with W&B for gradients etc.\n",
    "    if run:\n",
    "        wandb.watch(model, log='all', log_freq=100) # Log gradients and parameters every 100 batches\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing model/loss/optimizer: {e}\")\n",
    "    if run: run.finish()\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Train and Validate Model\n",
    "\n",
    "This section contains the main training loop over the specified number of epochs.\n",
    "\n",
    "**Inside each epoch:**\n",
    "* **Training Phase:**\n",
    "     * Set model to `train()` mode.\n",
    "     * Iterate through batches from `train_loader`.\n",
    "     * Move data to the correct device.\n",
    "     * Perform forward pass, calculate loss, perform backward pass, and update optimizer.\n",
    "     * Accumulate loss and predictions/targets for epoch metrics.\n",
    "     * Optionally log batch loss to W&B.\n",
    " * **Validation Phase:**\n",
    "     * Set model to `eval()` mode.\n",
    "     * Disable gradient calculations (`torch.no_grad()`).\n",
    "     * Iterate through batches from `val_loader`.\n",
    "     * Perform forward pass and calculate loss.\n",
    "     * Accumulate loss and predictions/targets for epoch metrics.\n",
    " * **End of Epoch:**\n",
    "     * Calculate and print average train/validation loss, MAE, and R2.\n",
    "     * Log epoch metrics to W&B.\n",
    "     * **Checkpointing:** If validation loss improved, save the model's state dictionary locally and log it as a W&B artifact tagged as 'best'.\n",
    "     * **Early Stopping:** Check if validation loss has stopped improving for `patience` epochs; if so, stop training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training and Validation Loop ---\n",
    "print(\"\\n--- Starting Model Training ---\")\n",
    "\n",
    "# Add tqdm for progress bars if you like (install with: pip install tqdm)\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "except ImportError:\n",
    "    print(\"Consider installing tqdm for progress bars: pip install tqdm\")\n",
    "    # Define a dummy tqdm if not installed\n",
    "    def tqdm(iterable, **kwargs):\n",
    "        return iterable\n",
    "\n",
    "best_val_loss = float('inf') # Initialize best validation loss to infinity\n",
    "epochs_no_improve = 0 # Counter for early stopping (optional)\n",
    "patience = 10 # Example: Stop after 10 epochs with no improvement (optional)\n",
    "\n",
    "# Make sure essential variables from previous cell exist\n",
    "required_vars = ['model', 'criterion', 'optimizer', 'train_loader', 'val_loader', 'device', 'HP', 'run_output_dir']\n",
    "if not all(v in locals() or v in globals() for v in required_vars):\n",
    "     print(\"Error: Not all required variables (model, criterion, etc.) are defined.\")\n",
    "     print(\"Please ensure the previous cells executed correctly.\")\n",
    "     # Exit or handle appropriately\n",
    "     exit()\n",
    "\n",
    "\n",
    "for epoch in range(HP['epochs']):\n",
    "    print(f\"\\n--- Epoch {epoch+1}/{HP['epochs']} ---\")\n",
    "    epoch_start_time = time.time()\n",
    "\n",
    "    # --- Training Phase ---\n",
    "    model.train() # Set model to training mode (enables dropout, batchnorm updates etc.)\n",
    "    train_loss = 0.0\n",
    "    train_targets_all = []\n",
    "    train_preds_all = []\n",
    "\n",
    "    # Use tqdm for a progress bar over batches\n",
    "    train_pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1} Train\")\n",
    "    for i, batch in train_pbar:\n",
    "        try:\n",
    "            sequences_padded, lengths, targets, masks = batch\n",
    "            # Move data to the appropriate device (GPU or CPU)\n",
    "            sequences_padded = sequences_padded.to(device)\n",
    "            targets = targets.to(device)\n",
    "            # Lengths and masks might be needed on CPU or GPU depending on usage\n",
    "\n",
    "            # 1. Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 2. Forward pass: Get model predictions\n",
    "            predictions = model(sequences_padded, lengths) # Pass lengths if model uses them\n",
    "\n",
    "            # 3. Calculate the loss\n",
    "            loss = criterion(predictions, targets)\n",
    "\n",
    "            # 4. Backward pass: Calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # 5. Optimizer step: Update weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss and results for metrics\n",
    "            train_loss += loss.item()\n",
    "            train_targets_all.extend(targets.detach().cpu().numpy().flatten())\n",
    "            train_preds_all.extend(predictions.detach().cpu().numpy().flatten())\n",
    "\n",
    "            # Update progress bar description\n",
    "            train_pbar.set_postfix({'batch_loss': loss.item()})\n",
    "\n",
    "            # Optional: Log batch loss to W&B periodically\n",
    "            if run and (i % 5 == 0): # Log every 5 batches\n",
    "                 wandb.log({'train/batch_loss': loss.item(), 'epoch': epoch + i/len(train_loader)})\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError during training batch {i}: {e}\")\n",
    "            # Decide how to handle - skip batch? stop training?\n",
    "            continue # Skip batch for now\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader) if len(train_loader) > 0 else 0\n",
    "    # Calculate training metrics for the epoch\n",
    "    train_mae = mean_absolute_error(train_targets_all, train_preds_all) if train_targets_all else 0\n",
    "    train_r2 = r2_score(train_targets_all, train_preds_all) if train_targets_all else 0\n",
    "\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "\n",
    "    model.eval() # Set model to evaluation mode (disables dropout, fixes batchnorm)\n",
    "    val_loss = 0.0\n",
    "    val_targets_all = []\n",
    "    val_preds_all = []\n",
    "\n",
    "    # Disable gradient calculations during validation\n",
    "    with torch.no_grad():\n",
    "        val_pbar = tqdm(enumerate(val_loader), total=len(val_loader), desc=f\"Epoch {epoch+1} Val\")\n",
    "        for i, batch in val_pbar:\n",
    "            try:\n",
    "                sequences_padded, lengths, targets, masks = batch\n",
    "                sequences_padded = sequences_padded.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                predictions = model(sequences_padded, lengths)\n",
    "\n",
    "                # Calculate loss\n",
    "                loss = criterion(predictions, targets)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                val_targets_all.extend(targets.detach().cpu().numpy().flatten())\n",
    "                val_preds_all.extend(predictions.detach().cpu().numpy().flatten())\n",
    "\n",
    "                val_pbar.set_postfix({'batch_loss': loss.item()})\n",
    "\n",
    "            except Exception as e:\n",
    "                 print(f\"\\nError during validation batch {i}: {e}\")\n",
    "                 continue # Skip batch\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader) if len(val_loader) > 0 else 0\n",
    "    # Calculate validation metrics for the epoch\n",
    "    val_mae = mean_absolute_error(val_targets_all, val_preds_all) if val_targets_all else 0\n",
    "    val_r2 = r2_score(val_targets_all, val_preds_all) if val_targets_all else 0\n",
    "\n",
    "\n",
    "    # --- End of Epoch ---\n",
    "    epoch_duration = time.time() - epoch_start_time\n",
    "    print(f\"Epoch {epoch+1}/{HP['epochs']} finished in {epoch_duration:.2f}s.\")\n",
    "    print(f\"  Train Loss: {avg_train_loss:.4f} | Train MAE: {train_mae:.4f} | Train R2: {train_r2:.4f}\")\n",
    "    print(f\"  Val Loss:   {avg_val_loss:.4f} | Val MAE:   {val_mae:.4f} | Val R2:   {val_r2:.4f}\")\n",
    "\n",
    "    # Log metrics to W&B\n",
    "    if run:\n",
    "        wandb.log({\n",
    "            'epoch': epoch + 1,\n",
    "            'train/epoch_loss': avg_train_loss,\n",
    "            'train/epoch_mae': train_mae,\n",
    "            'train/epoch_r2': train_r2,\n",
    "            'val/epoch_loss': avg_val_loss,\n",
    "            'val/epoch_mae': val_mae,\n",
    "            'val/epoch_r2': val_r2,\n",
    "            'epoch_duration_sec': epoch_duration\n",
    "        })\n",
    "\n",
    "    # --- Model Checkpointing ---\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_no_improve = 0 # Reset counter\n",
    "        # Define checkpoint path\n",
    "        checkpoint_path = run_output_dir / f\"best_model_epoch_{epoch+1}.pth\"\n",
    "        try:\n",
    "            # Save the model state dictionary\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f\"  Validation loss improved to {best_val_loss:.4f}. Saving model to {checkpoint_path}\")\n",
    "\n",
    "            # Log checkpoint as W&B artifact (optional but good)\n",
    "            if run:\n",
    "                print(\"  Logging checkpoint artifact to W&B...\")\n",
    "                artifact_name = f'baseline-lstm-model-checkpoint'\n",
    "                artifact_type = 'model'\n",
    "                description = f\"Model checkpoint at Epoch {epoch+1} with best val_loss: {best_val_loss:.4f}\"\n",
    "                model_artifact = wandb.Artifact(artifact_name, type=artifact_type, description=description,\n",
    "                                                metadata={'epoch': epoch+1, 'val_loss': best_val_loss,\n",
    "                                                          'val_mae': val_mae, 'val_r2': val_r2})\n",
    "                model_artifact.add_file(str(checkpoint_path))\n",
    "                run.log_artifact(model_artifact, aliases=['best', f'epoch_{epoch+1}']) # Alias 'best' points to this version\n",
    "                print(\"  Checkpoint artifact logged.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Error saving checkpoint: {e}\")\n",
    "\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"  Validation loss did not improve from {best_val_loss:.4f} ({epochs_no_improve}/{patience}).\")\n",
    "\n",
    "    # --- Early Stopping Check (Optional) ---\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"\\nEarly stopping triggered after {patience} epochs with no improvement.\")\n",
    "        break # Exit the training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# End of Training\n",
    "\n",
    "Summary of the best validation performance achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- End of Training ---\n",
    "print(\"\\n--- Training Complete ---\")\n",
    "print(f\"Best validation loss achieved: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Final step: Load best model and evaluate on test set (In a separate cell/script ideally) ---\n",
    "# print(\"\\nLoading best model for final test set evaluation...\")\n",
    "# best_model_path = run_output_dir / \"best_model_...\" # Find the actual best path\n",
    "# if best_model_path.exists():\n",
    "#      model.load_state_dict(torch.load(best_model_path))\n",
    "#      print(\"Best model loaded.\")\n",
    "#      # ... Add test set evaluation logic here ...\n",
    "# else:\n",
    "#      print(\"Warning: Best model checkpoint not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "# Save Run\n",
    "\n",
    "The best model checkpoint (`best_model_epoch_*.pth`) is saved locally and logged as the 'best' alias in the W&B artifacts for this run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Finish W&B Run ---\n",
    "print(\"\\n--- Finishing W&B run ---\")\n",
    "if run:\n",
    "    # Log best validation score as summary metric\n",
    "    run.summary[\"best_val_loss\"] = best_val_loss\n",
    "    run.finish()\n",
    "    print(\"W&B run finished.\")\n",
    "else:\n",
    "    print(\"No active W&B run to finish.\")\n",
    "\n",
    "print(\"\\nScript execution finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro_pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
